{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "59e7991e-ba6c-43ae-8018-387703abd204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Flatten, Dropout, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import keras\n",
    "import wandb\n",
    "from wandb.integration.keras import WandbMetricsLogger\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8089d1f2-5516-486b-b9a7-fe658d6acf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = \"adamata-selection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb57d3fc-e4a9-4b85-9cf1-3e306eec5f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = os.path.expanduser('dataset-resized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d514274-1b39-4703-ac61-46c41183fd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"loss\": \"categorical_crossentropy\",\n",
    "    \"metric\": \"accuracy\",\n",
    "    \"epoch\": 20,\n",
    "    \"batch_size\": 32\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "102b42cb-f24f-4d90-ae35-4c069d21f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(images_dir):\n",
    "    # Without data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rescale=1./255, \n",
    "        validation_split=0.2\n",
    "    )\n",
    "    \n",
    "    \n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        images_dir,\n",
    "        target_size=(128, 128),\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        class_mode='categorical',\n",
    "        subset='training'\n",
    "    )\n",
    "    \n",
    "    validation_generator = datagen.flow_from_directory(\n",
    "        images_dir,\n",
    "        target_size=(128, 128),\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        class_mode='categorical',\n",
    "        subset='validation'\n",
    "    )\n",
    "\n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dc8797-4e23-4602-874b-043f23877afb",
   "metadata": {},
   "source": [
    "## Store Data To Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6cf8514f-973d-4006-9902-0021f3fd41ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2024 images belonging to 6 classes.\n",
      "Found 503 images belonging to 6 classes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:gdizzpsl) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cosmic-cloud-26</strong> at: <a href='https://wandb.ai/adamata-selection/wandb-trash-classification/runs/gdizzpsl' target=\"_blank\">https://wandb.ai/adamata-selection/wandb-trash-classification/runs/gdizzpsl</a><br/> View project at: <a href='https://wandb.ai/adamata-selection/wandb-trash-classification' target=\"_blank\">https://wandb.ai/adamata-selection/wandb-trash-classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240520_133456-gdizzpsl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:gdizzpsl). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\adven\\Documents\\DSTI\\Career\\Applications\\Adamata\\trash-classification\\wandb\\run-20240520_133552-h1knb2ur</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adamata-selection/wandb-trash-classification/runs/h1knb2ur' target=\"_blank\">lemon-dragon-27</a></strong> to <a href='https://wandb.ai/adamata-selection/wandb-trash-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adamata-selection/wandb-trash-classification' target=\"_blank\">https://wandb.ai/adamata-selection/wandb-trash-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adamata-selection/wandb-trash-classification/runs/h1knb2ur' target=\"_blank\">https://wandb.ai/adamata-selection/wandb-trash-classification/runs/h1knb2ur</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 98.8%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lemon-dragon-27</strong> at: <a href='https://wandb.ai/adamata-selection/wandb-trash-classification/runs/h1knb2ur' target=\"_blank\">https://wandb.ai/adamata-selection/wandb-trash-classification/runs/h1knb2ur</a><br/> View project at: <a href='https://wandb.ai/adamata-selection/wandb-trash-classification' target=\"_blank\">https://wandb.ai/adamata-selection/wandb-trash-classification</a><br/>Synced 4 W&B file(s), 0 media file(s), 2526 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240520_133552-h1knb2ur\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "project = \"wandb-trash-classification\"\n",
    "\n",
    "model_use_case_id = \"model\"\n",
    "job_type = \"build_dataset\"\n",
    "\n",
    "train_generator, validation_generator = generate_data(images_dir)\n",
    "\n",
    "\n",
    "# Initialize a W&B run\n",
    "run = wandb.init(entity=entity, project=project, job_type=job_type)\n",
    "\n",
    "# Create W&B Table for training data\n",
    "train_table = wandb.Table(columns=[\"x_train\", \"y_train\"])\n",
    "for _ in range(len(train_generator)):\n",
    "    x_batch, y_batch = next(train_generator)\n",
    "    for x, y in zip(x_batch, y_batch):\n",
    "        train_table.add_data(wandb.Image(x), y)\n",
    "\n",
    "# Create W&B Table for validation data\n",
    "eval_table = wandb.Table(columns=[\"x_eval\", \"y_eval\"])\n",
    "for _ in range(len(validation_generator)):\n",
    "    x_batch, y_batch = next(validation_generator)\n",
    "    for x, y in zip(x_batch, y_batch):\n",
    "        eval_table.add_data(wandb.Image(x), y)\n",
    "\n",
    "# Create an artifact object\n",
    "artifact_name = \"{}_dataset\".format(model_use_case_id)\n",
    "artifact = wandb.Artifact(name=artifact_name, type=\"dataset\")\n",
    "\n",
    "# Add wandb.WBValue obj to the artifact.\n",
    "artifact.add(train_table, \"train_table\")\n",
    "artifact.add(eval_table, \"eval_table\")\n",
    "\n",
    "# Persist any changes made to the artifact.\n",
    "artifact.save()\n",
    "\n",
    "# Tell W&B this run is finished.\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa24fcd-1f9e-407e-8eeb-f1db787cffe6",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f4db7660-9873-439b-96d9-bef3d63ef784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:86qs3bdn) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wild-eon-29</strong> at: <a href='https://wandb.ai/adamata-selection/wandb-trash-classification/runs/86qs3bdn' target=\"_blank\">https://wandb.ai/adamata-selection/wandb-trash-classification/runs/86qs3bdn</a><br/> View project at: <a href='https://wandb.ai/adamata-selection/wandb-trash-classification' target=\"_blank\">https://wandb.ai/adamata-selection/wandb-trash-classification</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240520_134214-86qs3bdn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:86qs3bdn). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\adven\\Documents\\DSTI\\Career\\Applications\\Adamata\\trash-classification\\wandb\\run-20240520_134847-j0ku1651</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adamata-selection/wandb-trash-classification/runs/j0ku1651' target=\"_blank\">devoted-totem-30</a></strong> to <a href='https://wandb.ai/adamata-selection/wandb-trash-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adamata-selection/wandb-trash-classification' target=\"_blank\">https://wandb.ai/adamata-selection/wandb-trash-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adamata-selection/wandb-trash-classification/runs/j0ku1651' target=\"_blank\">https://wandb.ai/adamata-selection/wandb-trash-classification/runs/j0ku1651</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adven\\anaconda3\\envs\\trash-classification\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 ━━━━━━━━━━━━━━━━━━━━ 8:50 9s/step - accuracy: 0.3750 - loss: 3.140 ━━━━━━━━━━━━━━━━━━━━ 1:28 1s/step - accuracy: 0.2500 - loss: 14.85 ━━━━━━━━━━━━━━━━━━━━ 1:24 1s/step - accuracy: 0.2222 - loss: 19.10 ━━━━━━━━━━━━━━━━━━━━ 1:22 1s/step - accuracy: 0.2099 - loss: 21.16 ━━━━━━━━━━━━━━━━━━━━ 1:21 1s/step - accuracy: 0.2209 - loss: 21.83 ━━━━━━━━━━━━━━━━━━━━ 1:19 1s/step - accuracy: 0.2327 - loss: 22.46 ━━━━━━━━━━━━━━━━━━━━ 1:18 1s/step - accuracy: 0.2430 - loss: 22.84 ━━━━━━━━━━━━━━━━━━━━ 1:16 1s/step - accuracy: 0.2514 - loss: 22.94 ━━━━━━━━━━━━━━━━━━━━ 1:15 1s/step - accuracy: 0.2593 - loss: 22.97 ━━━━━━━━━━━━━━━━━━━━ 1:13 1s/step - accuracy: 0.2665 - loss: 22.90 ━━━━━━━━━━━━━━━━━━━━ 1:12 1s/step - accuracy: 0.2744 - loss: 22.76 ━━━━━━━━━━━━━━━━━━━━ 1:11 1s/step - accuracy: 0.2814 - loss: 22.56 ━━━━━━━━━━━━━━━━━━━━ 1:09 1s/step - accuracy: 0.2870 - loss: 22.36 ━━━━━━━━━━━━━━━━━━━━ 1:08 1s/step - accuracy: 0.2928 - loss: 22.13 ━━━━━━━━━━━━━━━━━━━━ 1:06 1s/step - accuracy: 0.2981 - loss: 21.91 ━━━━━━━━━━━━━━━━━━━━ 1:05 1s/step - accuracy: 0.3031 - loss: 21.68 ━━━━━━━━━━━━━━━━━━━━ 1:04 1s/step - accuracy: 0.3081 - loss: 21.45 ━━━━━━━━━━━━━━━━━━━━ 1:02 1s/step - accuracy: 0.3123 - loss: 21.23 ━━━━━━━━━━━━━━━━━━━━ 1:01 1s/step - accuracy: 0.3168 - loss: 21.00 ━━━━━━━━━━━━━━━━━━━━ 59s 1s/step - accuracy: 0.3208 - loss: 20.7805 ━━━━━━━━━━━━━━━━━━━━ 58s 1s/step - accuracy: 0.3248 - loss: 20.560 ━━━━━━━━━━━━━━━━━━━━ 57s 1s/step - accuracy: 0.3285 - loss: 20.348 ━━━━━━━━━━━━━━━━━━━━ 55s 1s/step - accuracy: 0.3322 - loss: 20.133 ━━━━━━━━━━━━━━━━━━━━ 54s 1s/step - accuracy: 0.3355 - loss: 19.926 ━━━━━━━━━━━━━━━━━━━━ 52s 1s/step - accuracy: 0.3388 - loss: 19.727 ━━━━━━━━━━━━━━━━━━━━ 51s 1s/step - accuracy: 0.3423 - loss: 19.528 ━━━━━━━━━━━━━━━━━━━━ 50s 1s/step - accuracy: 0.3456 - loss: 19.334 ━━━━━━━━━━━━━━━━━━━━ 48s 1s/step - accuracy: 0.3486 - loss: 19.151 ━━━━━━━━━━━━━━━━━━━━ 47s 1s/step - accuracy: 0.3516 - loss: 18.970 ━━━━━━━━━━━━━━━━━━━━ 46s 1s/step - accuracy: 0.3544 - loss: 18.792 ━━━━━━━━━━━━━━━━━━━━ 44s 1s/step - accuracy: 0.3571 - loss: 18.620 ━━━━━━━━━━━━━━━━━━━━ 43s 1s/step - accuracy: 0.3597 - loss: 18.452 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.3622 - loss: 18.292 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.3646 - loss: 18.135 ━━━━━━━━━━━━━━━━━━━━ 39s 1s/step - accuracy: 0.3669 - loss: 17.980 ━━━━━━━━━━━━━━━━━━━━ 37s 1s/step - accuracy: 0.3690 - loss: 17.834 ━━━━━━━━━━━━━━━━━━━━ 36s 1s/step - accuracy: 0.3711 - loss: 17.692 ━━━━━━━━━━━━━━━━━━━━ 34s 1s/step - accuracy: 0.3729 - loss: 17.555 ━━━━━━━━━━━━━━━━━━━━ 33s 1s/step - accuracy: 0.3748 - loss: 17.419 ━━━━━━━━━━━━━━━━━━━━ 31s 1s/step - accuracy: 0.3766 - loss: 17.289 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.3783 - loss: 17.161 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.3799 - loss: 17.037 ━━━━━━━━━━━━━━━━━━━━ 27s 1s/step - accuracy: 0.3815 - loss: 16.916 ━━━━━━━━━━━━━━━━━━━━ 26s 1s/step - accuracy: 0.3830 - loss: 16.796 ━━━━━━━━━━━━━━━━━━━━ 24s 1s/step - accuracy: 0.3845 - loss: 16.678 ━━━━━━━━━━━━━━━━━━━━ 23s 1s/step - accuracy: 0.3860 - loss: 16.562 ━━━━━━━━━━━━━━━━━━━━ 22s 1s/step - accuracy: 0.3874 - loss: 16.448 ━━━━━━━━━━━━━━━━━━━━ 20s 1s/step - accuracy: 0.3887 - loss: 16.336 ━━━━━━━━━━━━━━━━━━━━ 19s 1s/step - accuracy: 0.3901 - loss: 16.228 ━━━━━━━━━━━━━━━━━━━━ 17s 1s/step - accuracy: 0.3914 - loss: 16.123 ━━━━━━━━━━━━━━━━━━━━ 16s 1s/step - accuracy: 0.3928 - loss: 16.018 ━━━━━━━━━━━━━━━━━━━━ 15s 1s/step - accuracy: 0.3940 - loss: 15.915 ━━━━━━━━━━━━━━━━━━━━ 13s 1s/step - accuracy: 0.3952 - loss: 15.816 ━━━━━━━━━━━━━━━━━━━━ 12s 1s/step - accuracy: 0.3963 - loss: 15.719 ━━━━━━━━━━━━━━━━━━━━ 10s 1s/step - accuracy: 0.3974 - loss: 15.622 ━━━━━━━━━━━━━━━━━━━━ 9s 1s/step - accuracy: 0.3985 - loss: 15.527 ━━━━━━━━━━━━━━━━━━━━ 8s 1s/step - accuracy: 0.3996 - loss: 15.43 ━━━━━━━━━━━━━━━━━━━━ 6s 1s/step - accuracy: 0.4006 - loss: 15.33 ━━━━━━━━━━━━━━━━━━━━ 5s 1s/step - accuracy: 0.4017 - loss: 15.24 ━━━━━━━━━━━━━━━━━━━━ 4s 1s/step - accuracy: 0.4027 - loss: 15.15 ━━━━━━━━━━━━━━━━━━━━ 2s 1s/step - accuracy: 0.4038 - loss: 15.06 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step - accuracy: 0.4048 - loss: 14.97 ━━━━━━━━━━━━━━━━━━━━ 0s 1s/step - accuracy: 0.4058 - loss: 14.8878"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Unable to log learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 ━━━━━━━━━━━━━━━━━━━━ 98s 1s/step - accuracy: 0.4068 - loss: 14.8024 - val_accuracy: 0.2271 - val_loss: 5.7997\n",
      "Epoch 2/20\n",
      " 1/63 ━━━━━━━━━━━━━━━━━━━━ 1:25 1s/step - accuracy: 0.5312 - loss: 1.4262"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adven\\anaconda3\\envs\\trash-classification\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step - accuracy: 0.5312 - loss: 1.4262 - val_accuracy: 0.2174 - val_loss: 3.7785\n",
      "Epoch 3/20\n",
      "63/63 ━━━━━━━━━━━━━━━━━━━━ 2:01 2s/step - accuracy: 0.7188 - loss: 0.790 ━━━━━━━━━━━━━━━━━━━━ 1:16 1s/step - accuracy: 0.7031 - loss: 0.909 ━━━━━━━━━━━━━━━━━━━━ 1:17 1s/step - accuracy: 0.7083 - loss: 0.970 ━━━━━━━━━━━━━━━━━━━━ 1:15 1s/step - accuracy: 0.7129 - loss: 0.971 ━━━━━━━━━━━━━━━━━━━━ 1:15 1s/step - accuracy: 0.7141 - loss: 0.980 ━━━━━━━━━━━━━━━━━━━━ 1:12 1s/step - accuracy: 0.7114 - loss: 1.030 ━━━━━━━━━━━━━━━━━━━━ 1:10 1s/step - accuracy: 0.7073 - loss: 1.080 ━━━━━━━━━━━━━━━━━━━━ 1:09 1s/step - accuracy: 0.7044 - loss: 1.113 ━━━━━━━━━━━━━━━━━━━━ 1:08 1s/step - accuracy: 0.7017 - loss: 1.144 ━━━━━━━━━━━━━━━━━━━━ 1:06 1s/step - accuracy: 0.6984 - loss: 1.170 ━━━━━━━━━━━━━━━━━━━━ 1:05 1s/step - accuracy: 0.6943 - loss: 1.191 ━━━━━━━━━━━━━━━━━━━━ 1:04 1s/step - accuracy: 0.6916 - loss: 1.205 ━━━━━━━━━━━━━━━━━━━━ 1:02 1s/step - accuracy: 0.6885 - loss: 1.217 ━━━━━━━━━━━━━━━━━━━━ 1:01 1s/step - accuracy: 0.6854 - loss: 1.230 ━━━━━━━━━━━━━━━━━━━━ 57s 1s/step - accuracy: 0.6822 - loss: 1.241 ━━━━━━━━━━━━━━━━━━━━ 56s 1s/step - accuracy: 0.6794 - loss: 1.25 ━━━━━━━━━━━━━━━━━━━━ 56s 1s/step - accuracy: 0.6770 - loss: 1.26 ━━━━━━━━━━━━━━━━━━━━ 55s 1s/step - accuracy: 0.6747 - loss: 1.27 ━━━━━━━━━━━━━━━━━━━━ 54s 1s/step - accuracy: 0.6722 - loss: 1.27 ━━━━━━━━━━━━━━━━━━━━ 53s 1s/step - accuracy: 0.6696 - loss: 1.28 ━━━━━━━━━━━━━━━━━━━━ 52s 1s/step - accuracy: 0.6669 - loss: 1.29 ━━━━━━━━━━━━━━━━━━━━ 50s 1s/step - accuracy: 0.6639 - loss: 1.29 ━━━━━━━━━━━━━━━━━━━━ 49s 1s/step - accuracy: 0.6609 - loss: 1.30 ━━━━━━━━━━━━━━━━━━━━ 48s 1s/step - accuracy: 0.6583 - loss: 1.31 ━━━━━━━━━━━━━━━━━━━━ 47s 1s/step - accuracy: 0.6556 - loss: 1.31 ━━━━━━━━━━━━━━━━━━━━ 45s 1s/step - accuracy: 0.6531 - loss: 1.32 ━━━━━━━━━━━━━━━━━━━━ 44s 1s/step - accuracy: 0.6508 - loss: 1.33 ━━━━━━━━━━━━━━━━━━━━ 43s 1s/step - accuracy: 0.6485 - loss: 1.33 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.6464 - loss: 1.34 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.6443 - loss: 1.35 ━━━━━━━━━━━━━━━━━━━━ 39s 1s/step - accuracy: 0.6423 - loss: 1.36 ━━━━━━━━━━━━━━━━━━━━ 38s 1s/step - accuracy: 0.6407 - loss: 1.36 ━━━━━━━━━━━━━━━━━━━━ 37s 1s/step - accuracy: 0.6392 - loss: 1.37 ━━━━━━━━━━━━━━━━━━━━ 36s 1s/step - accuracy: 0.6378 - loss: 1.37 ━━━━━━━━━━━━━━━━━━━━ 35s 1s/step - accuracy: 0.6366 - loss: 1.38 ━━━━━━━━━━━━━━━━━━━━ 34s 1s/step - accuracy: 0.6354 - loss: 1.38 ━━━━━━━━━━━━━━━━━━━━ 32s 1s/step - accuracy: 0.6343 - loss: 1.38 ━━━━━━━━━━━━━━━━━━━━ 31s 1s/step - accuracy: 0.6332 - loss: 1.39 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.6321 - loss: 1.39 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.6310 - loss: 1.39 ━━━━━━━━━━━━━━━━━━━━ 27s 1s/step - accuracy: 0.6300 - loss: 1.40 ━━━━━━━━━━━━━━━━━━━━ 26s 1s/step - accuracy: 0.6290 - loss: 1.40 ━━━━━━━━━━━━━━━━━━━━ 25s 1s/step - accuracy: 0.6281 - loss: 1.40 ━━━━━━━━━━━━━━━━━━━━ 24s 1s/step - accuracy: 0.6274 - loss: 1.40 ━━━━━━━━━━━━━━━━━━━━ 22s 1s/step - accuracy: 0.6266 - loss: 1.41 ━━━━━━━━━━━━━━━━━━━━ 21s 1s/step - accuracy: 0.6258 - loss: 1.41 ━━━━━━━━━━━━━━━━━━━━ 20s 1s/step - accuracy: 0.6251 - loss: 1.41 ━━━━━━━━━━━━━━━━━━━━ 19s 1s/step - accuracy: 0.6245 - loss: 1.41 ━━━━━━━━━━━━━━━━━━━━ 17s 1s/step - accuracy: 0.6240 - loss: 1.42 ━━━━━━━━━━━━━━━━━━━━ 16s 1s/step - accuracy: 0.6234 - loss: 1.42 ━━━━━━━━━━━━━━━━━━━━ 15s 1s/step - accuracy: 0.6229 - loss: 1.42 ━━━━━━━━━━━━━━━━━━━━ 14s 1s/step - accuracy: 0.6224 - loss: 1.42 ━━━━━━━━━━━━━━━━━━━━ 12s 1s/step - accuracy: 0.6219 - loss: 1.42 ━━━━━━━━━━━━━━━━━━━━ 11s 1s/step - accuracy: 0.6214 - loss: 1.42 ━━━━━━━━━━━━━━━━━━━━ 10s 1s/step - accuracy: 0.6211 - loss: 1.42 ━━━━━━━━━━━━━━━━━━━━ 8s 1s/step - accuracy: 0.6207 - loss: 1.4300 ━━━━━━━━━━━━━━━━━━━━ 7s 1s/step - accuracy: 0.6203 - loss: 1.430 ━━━━━━━━━━━━━━━━━━━━ 6s 1s/step - accuracy: 0.6200 - loss: 1.431 ━━━━━━━━━━━━━━━━━━━━ 5s 1s/step - accuracy: 0.6196 - loss: 1.432 ━━━━━━━━━━━━━━━━━━━━ 3s 1s/step - accuracy: 0.6193 - loss: 1.433 ━━━━━━━━━━━━━━━━━━━━ 2s 1s/step - accuracy: 0.6189 - loss: 1.433 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step - accuracy: 0.6186 - loss: 1.434 ━━━━━━━━━━━━━━━━━━━━ 0s 1s/step - accuracy: 0.6182 - loss: 1.435 ━━━━━━━━━━━━━━━━━━━━ 86s 1s/step - accuracy: 0.6179 - loss: 1.4356 - val_accuracy: 0.1896 - val_loss: 9.2193\n",
      "Epoch 4/20\n",
      "63/63 ━━━━━━━━━━━━━━━━━━━━ 1:23 1s/step - accuracy: 0.6250 - loss: 1.085 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step - accuracy: 0.6250 - loss: 1.0851 - val_accuracy: 0.1304 - val_loss: 9.2315\n",
      "Epoch 5/20\n",
      "63/63 ━━━━━━━━━━━━━━━━━━━━ 2:01 2s/step - accuracy: 0.6562 - loss: 1.116 ━━━━━━━━━━━━━━━━━━━━ 1:23 1s/step - accuracy: 0.6953 - loss: 0.940 ━━━━━━━━━━━━━━━━━━━━ 1:21 1s/step - accuracy: 0.7066 - loss: 0.911 ━━━━━━━━━━━━━━━━━━━━ 1:19 1s/step - accuracy: 0.7077 - loss: 0.909 ━━━━━━━━━━━━━━━━━━━━ 1:18 1s/step - accuracy: 0.7061 - loss: 0.905 ━━━━━━━━━━━━━━━━━━━━ 1:17 1s/step - accuracy: 0.7048 - loss: 0.899 ━━━━━━━━━━━━━━━━━━━━ 1:16 1s/step - accuracy: 0.7023 - loss: 0.899 ━━━━━━━━━━━━━━━━━━━━ 1:14 1s/step - accuracy: 0.6985 - loss: 0.899 ━━━━━━━━━━━━━━━━━━━━ 1:12 1s/step - accuracy: 0.6950 - loss: 0.899 ━━━━━━━━━━━━━━━━━━━━ 1:11 1s/step - accuracy: 0.6914 - loss: 0.903 ━━━━━━━━━━━━━━━━━━━━ 1:09 1s/step - accuracy: 0.6861 - loss: 0.914 ━━━━━━━━━━━━━━━━━━━━ 1:08 1s/step - accuracy: 0.6828 - loss: 0.922 ━━━━━━━━━━━━━━━━━━━━ 1:07 1s/step - accuracy: 0.6807 - loss: 0.926 ━━━━━━━━━━━━━━━━━━━━ 1:05 1s/step - accuracy: 0.6793 - loss: 0.927 ━━━━━━━━━━━━━━━━━━━━ 1:04 1s/step - accuracy: 0.6774 - loss: 0.929 ━━━━━━━━━━━━━━━━━━━━ 1:00 1s/step - accuracy: 0.6760 - loss: 0.931 ━━━━━━━━━━━━━━━━━━━━ 59s 1s/step - accuracy: 0.6749 - loss: 0.931 ━━━━━━━━━━━━━━━━━━━━ 58s 1s/step - accuracy: 0.6743 - loss: 0.93 ━━━━━━━━━━━━━━━━━━━━ 57s 1s/step - accuracy: 0.6741 - loss: 0.93 ━━━━━━━━━━━━━━━━━━━━ 56s 1s/step - accuracy: 0.6743 - loss: 0.92 ━━━━━━━━━━━━━━━━━━━━ 55s 1s/step - accuracy: 0.6746 - loss: 0.92 ━━━━━━━━━━━━━━━━━━━━ 54s 1s/step - accuracy: 0.6746 - loss: 0.93 ━━━━━━━━━━━━━━━━━━━━ 52s 1s/step - accuracy: 0.6747 - loss: 0.93 ━━━━━━━━━━━━━━━━━━━━ 51s 1s/step - accuracy: 0.6749 - loss: 0.93 ━━━━━━━━━━━━━━━━━━━━ 50s 1s/step - accuracy: 0.6753 - loss: 0.93 ━━━━━━━━━━━━━━━━━━━━ 49s 1s/step - accuracy: 0.6757 - loss: 0.93 ━━━━━━━━━━━━━━━━━━━━ 47s 1s/step - accuracy: 0.6762 - loss: 0.93 ━━━━━━━━━━━━━━━━━━━━ 46s 1s/step - accuracy: 0.6767 - loss: 0.92 ━━━━━━━━━━━━━━━━━━━━ 45s 1s/step - accuracy: 0.6772 - loss: 0.92 ━━━━━━━━━━━━━━━━━━━━ 43s 1s/step - accuracy: 0.6777 - loss: 0.92 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.6780 - loss: 0.92 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.6781 - loss: 0.93 ━━━━━━━━━━━━━━━━━━━━ 39s 1s/step - accuracy: 0.6783 - loss: 0.93 ━━━━━━━━━━━━━━━━━━━━ 38s 1s/step - accuracy: 0.6783 - loss: 0.93 ━━━━━━━━━━━━━━━━━━━━ 37s 1s/step - accuracy: 0.6785 - loss: 0.93 ━━━━━━━━━━━━━━━━━━━━ 35s 1s/step - accuracy: 0.6785 - loss: 0.93 ━━━━━━━━━━━━━━━━━━━━ 34s 1s/step - accuracy: 0.6784 - loss: 0.93 ━━━━━━━━━━━━━━━━━━━━ 33s 1s/step - accuracy: 0.6783 - loss: 0.93 ━━━━━━━━━━━━━━━━━━━━ 31s 1s/step - accuracy: 0.6781 - loss: 0.93 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.6779 - loss: 0.93 ━━━━━━━━━━━━━━━━━━━━ 28s 1s/step - accuracy: 0.6777 - loss: 0.93 ━━━━━━━━━━━━━━━━━━━━ 27s 1s/step - accuracy: 0.6776 - loss: 0.93 ━━━━━━━━━━━━━━━━━━━━ 26s 1s/step - accuracy: 0.6775 - loss: 0.94 ━━━━━━━━━━━━━━━━━━━━ 25s 1s/step - accuracy: 0.6774 - loss: 0.94 ━━━━━━━━━━━━━━━━━━━━ 23s 1s/step - accuracy: 0.6773 - loss: 0.94 ━━━━━━━━━━━━━━━━━━━━ 22s 1s/step - accuracy: 0.6771 - loss: 0.94 ━━━━━━━━━━━━━━━━━━━━ 21s 1s/step - accuracy: 0.6770 - loss: 0.94 ━━━━━━━━━━━━━━━━━━━━ 19s 1s/step - accuracy: 0.6769 - loss: 0.94 ━━━━━━━━━━━━━━━━━━━━ 18s 1s/step - accuracy: 0.6768 - loss: 0.94 ━━━━━━━━━━━━━━━━━━━━ 17s 1s/step - accuracy: 0.6767 - loss: 0.94 ━━━━━━━━━━━━━━━━━━━━ 15s 1s/step - accuracy: 0.6766 - loss: 0.94 ━━━━━━━━━━━━━━━━━━━━ 14s 1s/step - accuracy: 0.6766 - loss: 0.94 ━━━━━━━━━━━━━━━━━━━━ 13s 1s/step - accuracy: 0.6765 - loss: 0.94 ━━━━━━━━━━━━━━━━━━━━ 11s 1s/step - accuracy: 0.6764 - loss: 0.94 ━━━━━━━━━━━━━━━━━━━━ 10s 1s/step - accuracy: 0.6764 - loss: 0.95 ━━━━━━━━━━━━━━━━━━━━ 9s 1s/step - accuracy: 0.6763 - loss: 0.9509 ━━━━━━━━━━━━━━━━━━━━ 7s 1s/step - accuracy: 0.6762 - loss: 0.951 ━━━━━━━━━━━━━━━━━━━━ 6s 1s/step - accuracy: 0.6761 - loss: 0.952 ━━━━━━━━━━━━━━━━━━━━ 5s 1s/step - accuracy: 0.6761 - loss: 0.952 ━━━━━━━━━━━━━━━━━━━━ 3s 1s/step - accuracy: 0.6761 - loss: 0.953 ━━━━━━━━━━━━━━━━━━━━ 2s 1s/step - accuracy: 0.6761 - loss: 0.953 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step - accuracy: 0.6760 - loss: 0.954 ━━━━━━━━━━━━━━━━━━━━ 0s 1s/step - accuracy: 0.6760 - loss: 0.954 ━━━━━━━━━━━━━━━━━━━━ 88s 1s/step - accuracy: 0.6759 - loss: 0.9551 - val_accuracy: 0.1167 - val_loss: 10.8335\n",
      "Epoch 6/20\n",
      "63/63 ━━━━━━━━━━━━━━━━━━━━ 1:18 1s/step - accuracy: 0.7188 - loss: 0.690 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step - accuracy: 0.7188 - loss: 0.6907 - val_accuracy: 0.1739 - val_loss: 9.5880\n",
      "Epoch 7/20\n",
      "63/63 ━━━━━━━━━━━━━━━━━━━━ 2:02 2s/step - accuracy: 0.6250 - loss: 0.804 ━━━━━━━━━━━━━━━━━━━━ 1:18 1s/step - accuracy: 0.6328 - loss: 0.856 ━━━━━━━━━━━━━━━━━━━━ 1:17 1s/step - accuracy: 0.6580 - loss: 0.823 ━━━━━━━━━━━━━━━━━━━━ 1:00 1s/step - accuracy: 0.6690 - loss: 0.813 ━━━━━━━━━━━━━━━━━━━━ 1:04 1s/step - accuracy: 0.6749 - loss: 0.814 ━━━━━━━━━━━━━━━━━━━━ 1:06 1s/step - accuracy: 0.6805 - loss: 0.811 ━━━━━━━━━━━━━━━━━━━━ 1:07 1s/step - accuracy: 0.6832 - loss: 0.809 ━━━━━━━━━━━━━━━━━━━━ 1:07 1s/step - accuracy: 0.6851 - loss: 0.810 ━━━━━━━━━━━━━━━━━━━━ 1:07 1s/step - accuracy: 0.6894 - loss: 0.805 ━━━━━━━━━━━━━━━━━━━━ 1:05 1s/step - accuracy: 0.6921 - loss: 0.801 ━━━━━━━━━━━━━━━━━━━━ 1:04 1s/step - accuracy: 0.6946 - loss: 0.803 ━━━━━━━━━━━━━━━━━━━━ 1:03 1s/step - accuracy: 0.6962 - loss: 0.805 ━━━━━━━━━━━━━━━━━━━━ 1:02 1s/step - accuracy: 0.6982 - loss: 0.805 ━━━━━━━━━━━━━━━━━━━━ 1:01 1s/step - accuracy: 0.7002 - loss: 0.805 ━━━━━━━━━━━━━━━━━━━━ 1:01 1s/step - accuracy: 0.7020 - loss: 0.803 ━━━━━━━━━━━━━━━━━━━━ 1:00 1s/step - accuracy: 0.7036 - loss: 0.802 ━━━━━━━━━━━━━━━━━━━━ 59s 1s/step - accuracy: 0.7051 - loss: 0.800 ━━━━━━━━━━━━━━━━━━━━ 58s 1s/step - accuracy: 0.7060 - loss: 0.79 ━━━━━━━━━━━━━━━━━━━━ 57s 1s/step - accuracy: 0.7070 - loss: 0.79 ━━━━━━━━━━━━━━━━━━━━ 55s 1s/step - accuracy: 0.7081 - loss: 0.79 ━━━━━━━━━━━━━━━━━━━━ 54s 1s/step - accuracy: 0.7090 - loss: 0.79 ━━━━━━━━━━━━━━━━━━━━ 53s 1s/step - accuracy: 0.7098 - loss: 0.79 ━━━━━━━━━━━━━━━━━━━━ 52s 1s/step - accuracy: 0.7104 - loss: 0.79 ━━━━━━━━━━━━━━━━━━━━ 51s 1s/step - accuracy: 0.7110 - loss: 0.79 ━━━━━━━━━━━━━━━━━━━━ 49s 1s/step - accuracy: 0.7115 - loss: 0.79 ━━━━━━━━━━━━━━━━━━━━ 48s 1s/step - accuracy: 0.7120 - loss: 0.79 ━━━━━━━━━━━━━━━━━━━━ 47s 1s/step - accuracy: 0.7124 - loss: 0.79 ━━━━━━━━━━━━━━━━━━━━ 46s 1s/step - accuracy: 0.7128 - loss: 0.79 ━━━━━━━━━━━━━━━━━━━━ 44s 1s/step - accuracy: 0.7132 - loss: 0.79 ━━━━━━━━━━━━━━━━━━━━ 43s 1s/step - accuracy: 0.7135 - loss: 0.79 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.7138 - loss: 0.79 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.7141 - loss: 0.79 ━━━━━━━━━━━━━━━━━━━━ 39s 1s/step - accuracy: 0.7145 - loss: 0.80 ━━━━━━━━━━━━━━━━━━━━ 38s 1s/step - accuracy: 0.7148 - loss: 0.80 ━━━━━━━━━━━━━━━━━━━━ 37s 1s/step - accuracy: 0.7151 - loss: 0.80 ━━━━━━━━━━━━━━━━━━━━ 35s 1s/step - accuracy: 0.7155 - loss: 0.80 ━━━━━━━━━━━━━━━━━━━━ 34s 1s/step - accuracy: 0.7158 - loss: 0.80 ━━━━━━━━━━━━━━━━━━━━ 33s 1s/step - accuracy: 0.7161 - loss: 0.80 ━━━━━━━━━━━━━━━━━━━━ 32s 1s/step - accuracy: 0.7165 - loss: 0.80 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.7170 - loss: 0.80 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.7173 - loss: 0.80 ━━━━━━━━━━━━━━━━━━━━ 28s 1s/step - accuracy: 0.7176 - loss: 0.80 ━━━━━━━━━━━━━━━━━━━━ 26s 1s/step - accuracy: 0.7178 - loss: 0.80 ━━━━━━━━━━━━━━━━━━━━ 25s 1s/step - accuracy: 0.7181 - loss: 0.80 ━━━━━━━━━━━━━━━━━━━━ 24s 1s/step - accuracy: 0.7184 - loss: 0.80 ━━━━━━━━━━━━━━━━━━━━ 22s 1s/step - accuracy: 0.7187 - loss: 0.80 ━━━━━━━━━━━━━━━━━━━━ 21s 1s/step - accuracy: 0.7189 - loss: 0.80 ━━━━━━━━━━━━━━━━━━━━ 20s 1s/step - accuracy: 0.7191 - loss: 0.81 ━━━━━━━━━━━━━━━━━━━━ 18s 1s/step - accuracy: 0.7194 - loss: 0.81 ━━━━━━━━━━━━━━━━━━━━ 17s 1s/step - accuracy: 0.7197 - loss: 0.81 ━━━━━━━━━━━━━━━━━━━━ 16s 1s/step - accuracy: 0.7199 - loss: 0.81 ━━━━━━━━━━━━━━━━━━━━ 14s 1s/step - accuracy: 0.7202 - loss: 0.81 ━━━━━━━━━━━━━━━━━━━━ 13s 1s/step - accuracy: 0.7205 - loss: 0.81 ━━━━━━━━━━━━━━━━━━━━ 12s 1s/step - accuracy: 0.7209 - loss: 0.81 ━━━━━━━━━━━━━━━━━━━━ 10s 1s/step - accuracy: 0.7212 - loss: 0.81 ━━━━━━━━━━━━━━━━━━━━ 9s 1s/step - accuracy: 0.7216 - loss: 0.8117 ━━━━━━━━━━━━━━━━━━━━ 8s 1s/step - accuracy: 0.7219 - loss: 0.812 ━━━━━━━━━━━━━━━━━━━━ 6s 1s/step - accuracy: 0.7222 - loss: 0.812 ━━━━━━━━━━━━━━━━━━━━ 5s 1s/step - accuracy: 0.7225 - loss: 0.812 ━━━━━━━━━━━━━━━━━━━━ 4s 1s/step - accuracy: 0.7228 - loss: 0.812 ━━━━━━━━━━━━━━━━━━━━ 2s 1s/step - accuracy: 0.7230 - loss: 0.813 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step - accuracy: 0.7233 - loss: 0.813 ━━━━━━━━━━━━━━━━━━━━ 0s 1s/step - accuracy: 0.7235 - loss: 0.813 ━━━━━━━━━━━━━━━━━━━━ 90s 1s/step - accuracy: 0.7238 - loss: 0.8139 - val_accuracy: 0.2146 - val_loss: 5.8322\n",
      "Epoch 8/20\n",
      "63/63 ━━━━━━━━━━━━━━━━━━━━ 1:19 1s/step - accuracy: 0.6875 - loss: 1.090 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - accuracy: 0.6875 - loss: 1.0906 - val_accuracy: 0.0870 - val_loss: 6.0003\n",
      "Epoch 9/20\n",
      "63/63 ━━━━━━━━━━━━━━━━━━━━ 2:02 2s/step - accuracy: 0.7500 - loss: 0.725 ━━━━━━━━━━━━━━━━━━━━ 1:17 1s/step - accuracy: 0.7500 - loss: 0.712 ━━━━━━━━━━━━━━━━━━━━ 1:17 1s/step - accuracy: 0.7535 - loss: 0.714 ━━━━━━━━━━━━━━━━━━━━ 1:17 1s/step - accuracy: 0.7526 - loss: 0.704 ━━━━━━━━━━━━━━━━━━━━ 1:16 1s/step - accuracy: 0.7521 - loss: 0.693 ━━━━━━━━━━━━━━━━━━━━ 1:14 1s/step - accuracy: 0.7491 - loss: 0.698 ━━━━━━━━━━━━━━━━━━━━ 1:14 1s/step - accuracy: 0.7493 - loss: 0.705 ━━━━━━━━━━━━━━━━━━━━ 1:13 1s/step - accuracy: 0.7489 - loss: 0.712 ━━━━━━━━━━━━━━━━━━━━ 1:12 1s/step - accuracy: 0.7509 - loss: 0.713 ━━━━━━━━━━━━━━━━━━━━ 1:11 1s/step - accuracy: 0.7530 - loss: 0.712 ━━━━━━━━━━━━━━━━━━━━ 1:10 1s/step - accuracy: 0.7545 - loss: 0.712 ━━━━━━━━━━━━━━━━━━━━ 1:09 1s/step - accuracy: 0.7561 - loss: 0.711 ━━━━━━━━━━━━━━━━━━━━ 1:07 1s/step - accuracy: 0.7575 - loss: 0.711 ━━━━━━━━━━━━━━━━━━━━ 1:06 1s/step - accuracy: 0.7589 - loss: 0.710 ━━━━━━━━━━━━━━━━━━━━ 1:05 1s/step - accuracy: 0.7602 - loss: 0.708 ━━━━━━━━━━━━━━━━━━━━ 1:04 1s/step - accuracy: 0.7613 - loss: 0.706 ━━━━━━━━━━━━━━━━━━━━ 1:02 1s/step - accuracy: 0.7626 - loss: 0.703 ━━━━━━━━━━━━━━━━━━━━ 1:01 1s/step - accuracy: 0.7636 - loss: 0.700 ━━━━━━━━━━━━━━━━━━━━ 1:00 1s/step - accuracy: 0.7642 - loss: 0.697 ━━━━━━━━━━━━━━━━━━━━ 58s 1s/step - accuracy: 0.7648 - loss: 0.695 ━━━━━━━━━━━━━━━━━━━━ 57s 1s/step - accuracy: 0.7652 - loss: 0.69 ━━━━━━━━━━━━━━━━━━━━ 56s 1s/step - accuracy: 0.7655 - loss: 0.69 ━━━━━━━━━━━━━━━━━━━━ 54s 1s/step - accuracy: 0.7658 - loss: 0.68 ━━━━━━━━━━━━━━━━━━━━ 53s 1s/step - accuracy: 0.7661 - loss: 0.68 ━━━━━━━━━━━━━━━━━━━━ 52s 1s/step - accuracy: 0.7664 - loss: 0.68 ━━━━━━━━━━━━━━━━━━━━ 50s 1s/step - accuracy: 0.7667 - loss: 0.68 ━━━━━━━━━━━━━━━━━━━━ 49s 1s/step - accuracy: 0.7667 - loss: 0.68 ━━━━━━━━━━━━━━━━━━━━ 48s 1s/step - accuracy: 0.7669 - loss: 0.68 ━━━━━━━━━━━━━━━━━━━━ 46s 1s/step - accuracy: 0.7672 - loss: 0.68 ━━━━━━━━━━━━━━━━━━━━ 45s 1s/step - accuracy: 0.7675 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 43s 1s/step - accuracy: 0.7680 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.7686 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.7691 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 39s 1s/step - accuracy: 0.7695 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 38s 1s/step - accuracy: 0.7698 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 36s 1s/step - accuracy: 0.7701 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 35s 1s/step - accuracy: 0.7703 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 33s 1s/step - accuracy: 0.7705 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 32s 1s/step - accuracy: 0.7706 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 31s 1s/step - accuracy: 0.7708 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.7708 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 28s 1s/step - accuracy: 0.7709 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 27s 1s/step - accuracy: 0.7709 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 25s 1s/step - accuracy: 0.7709 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 24s 1s/step - accuracy: 0.7709 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 23s 1s/step - accuracy: 0.7708 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 21s 1s/step - accuracy: 0.7709 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 20s 1s/step - accuracy: 0.7709 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 18s 1s/step - accuracy: 0.7709 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 17s 1s/step - accuracy: 0.7709 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 16s 1s/step - accuracy: 0.7709 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 14s 1s/step - accuracy: 0.7710 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 13s 1s/step - accuracy: 0.7710 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 12s 1s/step - accuracy: 0.7711 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 10s 1s/step - accuracy: 0.7711 - loss: 0.67 ━━━━━━━━━━━━━━━━━━━━ 9s 1s/step - accuracy: 0.7712 - loss: 0.6729 ━━━━━━━━━━━━━━━━━━━━ 8s 1s/step - accuracy: 0.7713 - loss: 0.672 ━━━━━━━━━━━━━━━━━━━━ 6s 1s/step - accuracy: 0.7714 - loss: 0.672 ━━━━━━━━━━━━━━━━━━━━ 5s 1s/step - accuracy: 0.7714 - loss: 0.672 ━━━━━━━━━━━━━━━━━━━━ 4s 1s/step - accuracy: 0.7714 - loss: 0.672 ━━━━━━━━━━━━━━━━━━━━ 2s 1s/step - accuracy: 0.7714 - loss: 0.672 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step - accuracy: 0.7715 - loss: 0.672 ━━━━━━━━━━━━━━━━━━━━ 0s 1s/step - accuracy: 0.7715 - loss: 0.672 ━━━━━━━━━━━━━━━━━━━━ 91s 1s/step - accuracy: 0.7715 - loss: 0.6729 - val_accuracy: 0.2521 - val_loss: 7.3784\n",
      "Epoch 10/20\n",
      "63/63 ━━━━━━━━━━━━━━━━━━━━ 1:25 1s/step - accuracy: 0.7500 - loss: 0.739 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step - accuracy: 0.7500 - loss: 0.7393 - val_accuracy: 0.2174 - val_loss: 7.3133\n",
      "Epoch 11/20\n",
      "63/63 ━━━━━━━━━━━━━━━━━━━━ 2:02 2s/step - accuracy: 0.8750 - loss: 0.381 ━━━━━━━━━━━━━━━━━━━━ 1:20 1s/step - accuracy: 0.8594 - loss: 0.477 ━━━━━━━━━━━━━━━━━━━━ 1:18 1s/step - accuracy: 0.8403 - loss: 0.548 ━━━━━━━━━━━━━━━━━━━━ 1:17 1s/step - accuracy: 0.8353 - loss: 0.559 ━━━━━━━━━━━━━━━━━━━━ 1:16 1s/step - accuracy: 0.8357 - loss: 0.556 ━━━━━━━━━━━━━━━━━━━━ 1:15 1s/step - accuracy: 0.8327 - loss: 0.563 ━━━━━━━━━━━━━━━━━━━━ 1:15 1s/step - accuracy: 0.8298 - loss: 0.563 ━━━━━━━━━━━━━━━━━━━━ 1:13 1s/step - accuracy: 0.8267 - loss: 0.572 ━━━━━━━━━━━━━━━━━━━━ 1:13 1s/step - accuracy: 0.8243 - loss: 0.576 ━━━━━━━━━━━━━━━━━━━━ 1:11 1s/step - accuracy: 0.8225 - loss: 0.579 ━━━━━━━━━━━━━━━━━━━━ 1:10 1s/step - accuracy: 0.8208 - loss: 0.582 ━━━━━━━━━━━━━━━━━━━━ 1:09 1s/step - accuracy: 0.8191 - loss: 0.585 ━━━━━━━━━━━━━━━━━━━━ 1:08 1s/step - accuracy: 0.8184 - loss: 0.585 ━━━━━━━━━━━━━━━━━━━━ 1:06 1s/step - accuracy: 0.8178 - loss: 0.588 ━━━━━━━━━━━━━━━━━━━━ 1:05 1s/step - accuracy: 0.8174 - loss: 0.590 ━━━━━━━━━━━━━━━━━━━━ 1:04 1s/step - accuracy: 0.8173 - loss: 0.591 ━━━━━━━━━━━━━━━━━━━━ 1:02 1s/step - accuracy: 0.8172 - loss: 0.592 ━━━━━━━━━━━━━━━━━━━━ 1:01 1s/step - accuracy: 0.8167 - loss: 0.593 ━━━━━━━━━━━━━━━━━━━━ 1:00 1s/step - accuracy: 0.8163 - loss: 0.594 ━━━━━━━━━━━━━━━━━━━━ 58s 1s/step - accuracy: 0.8157 - loss: 0.597 ━━━━━━━━━━━━━━━━━━━━ 57s 1s/step - accuracy: 0.8152 - loss: 0.60 ━━━━━━━━━━━━━━━━━━━━ 56s 1s/step - accuracy: 0.8149 - loss: 0.60 ━━━━━━━━━━━━━━━━━━━━ 54s 1s/step - accuracy: 0.8146 - loss: 0.60 ━━━━━━━━━━━━━━━━━━━━ 53s 1s/step - accuracy: 0.8144 - loss: 0.60 ━━━━━━━━━━━━━━━━━━━━ 52s 1s/step - accuracy: 0.8142 - loss: 0.60 ━━━━━━━━━━━━━━━━━━━━ 50s 1s/step - accuracy: 0.8137 - loss: 0.60 ━━━━━━━━━━━━━━━━━━━━ 49s 1s/step - accuracy: 0.8134 - loss: 0.61 ━━━━━━━━━━━━━━━━━━━━ 48s 1s/step - accuracy: 0.8132 - loss: 0.61 ━━━━━━━━━━━━━━━━━━━━ 46s 1s/step - accuracy: 0.8129 - loss: 0.61 ━━━━━━━━━━━━━━━━━━━━ 45s 1s/step - accuracy: 0.8127 - loss: 0.61 ━━━━━━━━━━━━━━━━━━━━ 43s 1s/step - accuracy: 0.8126 - loss: 0.61 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8124 - loss: 0.61 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8122 - loss: 0.61 ━━━━━━━━━━━━━━━━━━━━ 39s 1s/step - accuracy: 0.8120 - loss: 0.61 ━━━━━━━━━━━━━━━━━━━━ 38s 1s/step - accuracy: 0.8118 - loss: 0.62 ━━━━━━━━━━━━━━━━━━━━ 37s 1s/step - accuracy: 0.8116 - loss: 0.62 ━━━━━━━━━━━━━━━━━━━━ 35s 1s/step - accuracy: 0.8115 - loss: 0.62 ━━━━━━━━━━━━━━━━━━━━ 34s 1s/step - accuracy: 0.8114 - loss: 0.62 ━━━━━━━━━━━━━━━━━━━━ 32s 1s/step - accuracy: 0.8112 - loss: 0.62 ━━━━━━━━━━━━━━━━━━━━ 31s 1s/step - accuracy: 0.8111 - loss: 0.62 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.8111 - loss: 0.62 ━━━━━━━━━━━━━━━━━━━━ 28s 1s/step - accuracy: 0.8110 - loss: 0.62 ━━━━━━━━━━━━━━━━━━━━ 27s 1s/step - accuracy: 0.8109 - loss: 0.62 ━━━━━━━━━━━━━━━━━━━━ 26s 1s/step - accuracy: 0.8107 - loss: 0.62 ━━━━━━━━━━━━━━━━━━━━ 24s 1s/step - accuracy: 0.8106 - loss: 0.62 ━━━━━━━━━━━━━━━━━━━━ 23s 1s/step - accuracy: 0.8106 - loss: 0.62 ━━━━━━━━━━━━━━━━━━━━ 21s 1s/step - accuracy: 0.8105 - loss: 0.62 ━━━━━━━━━━━━━━━━━━━━ 20s 1s/step - accuracy: 0.8105 - loss: 0.62 ━━━━━━━━━━━━━━━━━━━━ 19s 1s/step - accuracy: 0.8103 - loss: 0.62 ━━━━━━━━━━━━━━━━━━━━ 17s 1s/step - accuracy: 0.8102 - loss: 0.62 ━━━━━━━━━━━━━━━━━━━━ 16s 1s/step - accuracy: 0.8100 - loss: 0.62 ━━━━━━━━━━━━━━━━━━━━ 14s 1s/step - accuracy: 0.8098 - loss: 0.62 ━━━━━━━━━━━━━━━━━━━━ 13s 1s/step - accuracy: 0.8096 - loss: 0.62 ━━━━━━━━━━━━━━━━━━━━ 12s 1s/step - accuracy: 0.8095 - loss: 0.62 ━━━━━━━━━━━━━━━━━━━━ 10s 1s/step - accuracy: 0.8093 - loss: 0.62 ━━━━━━━━━━━━━━━━━━━━ 9s 1s/step - accuracy: 0.8091 - loss: 0.6273 ━━━━━━━━━━━━━━━━━━━━ 8s 1s/step - accuracy: 0.8089 - loss: 0.627 ━━━━━━━━━━━━━━━━━━━━ 6s 1s/step - accuracy: 0.8087 - loss: 0.627 ━━━━━━━━━━━━━━━━━━━━ 5s 1s/step - accuracy: 0.8086 - loss: 0.628 ━━━━━━━━━━━━━━━━━━━━ 4s 1s/step - accuracy: 0.8084 - loss: 0.628 ━━━━━━━━━━━━━━━━━━━━ 2s 1s/step - accuracy: 0.8083 - loss: 0.628 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step - accuracy: 0.8081 - loss: 0.628 ━━━━━━━━━━━━━━━━━━━━ 0s 1s/step - accuracy: 0.8079 - loss: 0.628 ━━━━━━━━━━━━━━━━━━━━ 91s 1s/step - accuracy: 0.8077 - loss: 0.6292 - val_accuracy: 0.2583 - val_loss: 5.4969\n",
      "Epoch 12/20\n",
      "63/63 ━━━━━━━━━━━━━━━━━━━━ 1:24 1s/step - accuracy: 0.8125 - loss: 0.458 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step - accuracy: 0.8125 - loss: 0.4589 - val_accuracy: 0.2174 - val_loss: 4.8453\n",
      "Epoch 13/20\n",
      "63/63 ━━━━━━━━━━━━━━━━━━━━ 2:05 2s/step - accuracy: 0.8125 - loss: 0.559 ━━━━━━━━━━━━━━━━━━━━ 1:22 1s/step - accuracy: 0.8203 - loss: 0.529 ━━━━━━━━━━━━━━━━━━━━ 1:21 1s/step - accuracy: 0.8142 - loss: 0.520 ━━━━━━━━━━━━━━━━━━━━ 1:20 1s/step - accuracy: 0.8099 - loss: 0.517 ━━━━━━━━━━━━━━━━━━━━ 1:18 1s/step - accuracy: 0.8092 - loss: 0.517 ━━━━━━━━━━━━━━━━━━━━ 1:18 1s/step - accuracy: 0.8097 - loss: 0.516 ━━━━━━━━━━━━━━━━━━━━ 1:17 1s/step - accuracy: 0.8108 - loss: 0.512 ━━━━━━━━━━━━━━━━━━━━ 1:15 1s/step - accuracy: 0.8129 - loss: 0.506 ━━━━━━━━━━━━━━━━━━━━ 1:08 1s/step - accuracy: 0.8139 - loss: 0.503 ━━━━━━━━━━━━━━━━━━━━ 1:07 1s/step - accuracy: 0.8150 - loss: 0.500 ━━━━━━━━━━━━━━━━━━━━ 1:06 1s/step - accuracy: 0.8152 - loss: 0.500 ━━━━━━━━━━━━━━━━━━━━ 1:05 1s/step - accuracy: 0.8160 - loss: 0.501 ━━━━━━━━━━━━━━━━━━━━ 1:04 1s/step - accuracy: 0.8168 - loss: 0.501 ━━━━━━━━━━━━━━━━━━━━ 1:03 1s/step - accuracy: 0.8172 - loss: 0.503 ━━━━━━━━━━━━━━━━━━━━ 1:02 1s/step - accuracy: 0.8173 - loss: 0.504 ━━━━━━━━━━━━━━━━━━━━ 1:01 1s/step - accuracy: 0.8169 - loss: 0.507 ━━━━━━━━━━━━━━━━━━━━ 1:00 1s/step - accuracy: 0.8164 - loss: 0.511 ━━━━━━━━━━━━━━━━━━━━ 59s 1s/step - accuracy: 0.8161 - loss: 0.515 ━━━━━━━━━━━━━━━━━━━━ 58s 1s/step - accuracy: 0.8162 - loss: 0.51 ━━━━━━━━━━━━━━━━━━━━ 56s 1s/step - accuracy: 0.8165 - loss: 0.52 ━━━━━━━━━━━━━━━━━━━━ 55s 1s/step - accuracy: 0.8166 - loss: 0.52 ━━━━━━━━━━━━━━━━━━━━ 54s 1s/step - accuracy: 0.8166 - loss: 0.52 ━━━━━━━━━━━━━━━━━━━━ 53s 1s/step - accuracy: 0.8165 - loss: 0.52 ━━━━━━━━━━━━━━━━━━━━ 51s 1s/step - accuracy: 0.8164 - loss: 0.53 ━━━━━━━━━━━━━━━━━━━━ 50s 1s/step - accuracy: 0.8164 - loss: 0.53 ━━━━━━━━━━━━━━━━━━━━ 49s 1s/step - accuracy: 0.8164 - loss: 0.53 ━━━━━━━━━━━━━━━━━━━━ 47s 1s/step - accuracy: 0.8164 - loss: 0.53 ━━━━━━━━━━━━━━━━━━━━ 46s 1s/step - accuracy: 0.8165 - loss: 0.53 ━━━━━━━━━━━━━━━━━━━━ 45s 1s/step - accuracy: 0.8166 - loss: 0.53 ━━━━━━━━━━━━━━━━━━━━ 43s 1s/step - accuracy: 0.8168 - loss: 0.53 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8168 - loss: 0.53 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.8168 - loss: 0.54 ━━━━━━━━━━━━━━━━━━━━ 39s 1s/step - accuracy: 0.8168 - loss: 0.54 ━━━━━━━━━━━━━━━━━━━━ 38s 1s/step - accuracy: 0.8168 - loss: 0.54 ━━━━━━━━━━━━━━━━━━━━ 36s 1s/step - accuracy: 0.8166 - loss: 0.54 ━━━━━━━━━━━━━━━━━━━━ 35s 1s/step - accuracy: 0.8165 - loss: 0.54 ━━━━━━━━━━━━━━━━━━━━ 34s 1s/step - accuracy: 0.8165 - loss: 0.54 ━━━━━━━━━━━━━━━━━━━━ 33s 1s/step - accuracy: 0.8165 - loss: 0.54 ━━━━━━━━━━━━━━━━━━━━ 31s 1s/step - accuracy: 0.8165 - loss: 0.54 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.8166 - loss: 0.54 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.8167 - loss: 0.54 ━━━━━━━━━━━━━━━━━━━━ 27s 1s/step - accuracy: 0.8168 - loss: 0.54 ━━━━━━━━━━━━━━━━━━━━ 26s 1s/step - accuracy: 0.8168 - loss: 0.54 ━━━━━━━━━━━━━━━━━━━━ 25s 1s/step - accuracy: 0.8168 - loss: 0.54 ━━━━━━━━━━━━━━━━━━━━ 23s 1s/step - accuracy: 0.8168 - loss: 0.54 ━━━━━━━━━━━━━━━━━━━━ 22s 1s/step - accuracy: 0.8168 - loss: 0.55 ━━━━━━━━━━━━━━━━━━━━ 21s 1s/step - accuracy: 0.8168 - loss: 0.55 ━━━━━━━━━━━━━━━━━━━━ 19s 1s/step - accuracy: 0.8168 - loss: 0.55 ━━━━━━━━━━━━━━━━━━━━ 18s 1s/step - accuracy: 0.8167 - loss: 0.55 ━━━━━━━━━━━━━━━━━━━━ 17s 1s/step - accuracy: 0.8167 - loss: 0.55 ━━━━━━━━━━━━━━━━━━━━ 15s 1s/step - accuracy: 0.8166 - loss: 0.55 ━━━━━━━━━━━━━━━━━━━━ 14s 1s/step - accuracy: 0.8165 - loss: 0.55 ━━━━━━━━━━━━━━━━━━━━ 13s 1s/step - accuracy: 0.8164 - loss: 0.55 ━━━━━━━━━━━━━━━━━━━━ 12s 1s/step - accuracy: 0.8162 - loss: 0.55 ━━━━━━━━━━━━━━━━━━━━ 10s 1s/step - accuracy: 0.8161 - loss: 0.55 ━━━━━━━━━━━━━━━━━━━━ 9s 1s/step - accuracy: 0.8159 - loss: 0.5560 ━━━━━━━━━━━━━━━━━━━━ 8s 1s/step - accuracy: 0.8158 - loss: 0.556 ━━━━━━━━━━━━━━━━━━━━ 6s 1s/step - accuracy: 0.8157 - loss: 0.557 ━━━━━━━━━━━━━━━━━━━━ 5s 1s/step - accuracy: 0.8156 - loss: 0.557 ━━━━━━━━━━━━━━━━━━━━ 4s 1s/step - accuracy: 0.8155 - loss: 0.558 ━━━━━━━━━━━━━━━━━━━━ 2s 1s/step - accuracy: 0.8154 - loss: 0.559 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step - accuracy: 0.8153 - loss: 0.559 ━━━━━━━━━━━━━━━━━━━━ 0s 1s/step - accuracy: 0.8153 - loss: 0.560 ━━━━━━━━━━━━━━━━━━━━ 90s 1s/step - accuracy: 0.8152 - loss: 0.5608 - val_accuracy: 0.3417 - val_loss: 3.4781\n",
      "Epoch 14/20\n",
      "63/63 ━━━━━━━━━━━━━━━━━━━━ 1:15 1s/step - accuracy: 0.8438 - loss: 0.766 ━━━━━━━━━━━━━━━━━━━━ 2s 5ms/step - accuracy: 0.8438 - loss: 0.7663 - val_accuracy: 0.4783 - val_loss: 1.9447\n",
      "Epoch 15/20\n",
      "63/63 ━━━━━━━━━━━━━━━━━━━━ 2:05 2s/step - accuracy: 0.7812 - loss: 0.451 ━━━━━━━━━━━━━━━━━━━━ 1:28 1s/step - accuracy: 0.7891 - loss: 0.434 ━━━━━━━━━━━━━━━━━━━━ 1:24 1s/step - accuracy: 0.7934 - loss: 0.429 ━━━━━━━━━━━━━━━━━━━━ 1:21 1s/step - accuracy: 0.7982 - loss: 0.436 ━━━━━━━━━━━━━━━━━━━━ 1:18 1s/step - accuracy: 0.8073 - loss: 0.429 ━━━━━━━━━━━━━━━━━━━━ 1:17 1s/step - accuracy: 0.8151 - loss: 0.424 ━━━━━━━━━━━━━━━━━━━━ 1:15 1s/step - accuracy: 0.8205 - loss: 0.422 ━━━━━━━━━━━━━━━━━━━━ 1:13 1s/step - accuracy: 0.8234 - loss: 0.427 ━━━━━━━━━━━━━━━━━━━━ 1:12 1s/step - accuracy: 0.8253 - loss: 0.432 ━━━━━━━━━━━━━━━━━━━━ 1:11 1s/step - accuracy: 0.8274 - loss: 0.434 ━━━━━━━━━━━━━━━━━━━━ 1:09 1s/step - accuracy: 0.8289 - loss: 0.436 ━━━━━━━━━━━━━━━━━━━━ 1:08 1s/step - accuracy: 0.8304 - loss: 0.437 ━━━━━━━━━━━━━━━━━━━━ 1:07 1s/step - accuracy: 0.8323 - loss: 0.436 ━━━━━━━━━━━━━━━━━━━━ 1:05 1s/step - accuracy: 0.8333 - loss: 0.437 ━━━━━━━━━━━━━━━━━━━━ 1:04 1s/step - accuracy: 0.8344 - loss: 0.436 ━━━━━━━━━━━━━━━━━━━━ 1:02 1s/step - accuracy: 0.8355 - loss: 0.436 ━━━━━━━━━━━━━━━━━━━━ 1:01 1s/step - accuracy: 0.8365 - loss: 0.435 ━━━━━━━━━━━━━━━━━━━━ 1:00 1s/step - accuracy: 0.8377 - loss: 0.433 ━━━━━━━━━━━━━━━━━━━━ 58s 1s/step - accuracy: 0.8386 - loss: 0.435 ━━━━━━━━━━━━━━━━━━━━ 57s 1s/step - accuracy: 0.8396 - loss: 0.43 ━━━━━━━━━━━━━━━━━━━━ 56s 1s/step - accuracy: 0.8406 - loss: 0.43 ━━━━━━━━━━━━━━━━━━━━ 55s 1s/step - accuracy: 0.8417 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 54s 1s/step - accuracy: 0.8428 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 53s 1s/step - accuracy: 0.8436 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 52s 1s/step - accuracy: 0.8443 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 49s 1s/step - accuracy: 0.8451 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 46s 1s/step - accuracy: 0.8459 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 44s 1s/step - accuracy: 0.8467 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.8473 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 39s 1s/step - accuracy: 0.8479 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 37s 1s/step - accuracy: 0.8483 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 35s 1s/step - accuracy: 0.8488 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 34s 1s/step - accuracy: 0.8492 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 32s 1s/step - accuracy: 0.8496 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.8500 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 28s 1s/step - accuracy: 0.8504 - loss: 0.45 ━━━━━━━━━━━━━━━━━━━━ 27s 1s/step - accuracy: 0.8507 - loss: 0.45 ━━━━━━━━━━━━━━━━━━━━ 25s 1s/step - accuracy: 0.8509 - loss: 0.45 ━━━━━━━━━━━━━━━━━━━━ 24s 1s/step - accuracy: 0.8512 - loss: 0.45 ━━━━━━━━━━━━━━━━━━━━ 22s 998ms/step - accuracy: 0.8514 - loss: 0.450 ━━━━━━━━━━━━━━━━━━━━ 21s 984ms/step - accuracy: 0.8517 - loss: 0.450 ━━━━━━━━━━━━━━━━━━━━ 20s 971ms/step - accuracy: 0.8520 - loss: 0.449 ━━━━━━━━━━━━━━━━━━━━ 19s 958ms/step - accuracy: 0.8522 - loss: 0.449 ━━━━━━━━━━━━━━━━━━━━ 17s 946ms/step - accuracy: 0.8525 - loss: 0.449 ━━━━━━━━━━━━━━━━━━━━ 16s 934ms/step - accuracy: 0.8528 - loss: 0.448 ━━━━━━━━━━━━━━━━━━━━ 15s 922ms/step - accuracy: 0.8531 - loss: 0.448 ━━━━━━━━━━━━━━━━━━━━ 14s 911ms/step - accuracy: 0.8533 - loss: 0.447 ━━━━━━━━━━━━━━━━━━━━ 13s 900ms/step - accuracy: 0.8536 - loss: 0.447 ━━━━━━━━━━━━━━━━━━━━ 12s 889ms/step - accuracy: 0.8538 - loss: 0.447 ━━━━━━━━━━━━━━━━━━━━ 11s 879ms/step - accuracy: 0.8541 - loss: 0.447 ━━━━━━━━━━━━━━━━━━━━ 10s 870ms/step - accuracy: 0.8544 - loss: 0.447 ━━━━━━━━━━━━━━━━━━━━ 9s 862ms/step - accuracy: 0.8546 - loss: 0.447 ━━━━━━━━━━━━━━━━━━━━ 8s 854ms/step - accuracy: 0.8548 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 7s 845ms/step - accuracy: 0.8550 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 6s 836ms/step - accuracy: 0.8552 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 5s 828ms/step - accuracy: 0.8554 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 4s 820ms/step - accuracy: 0.8556 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 4s 813ms/step - accuracy: 0.8557 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 3s 806ms/step - accuracy: 0.8559 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 2s 799ms/step - accuracy: 0.8560 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 1s 793ms/step - accuracy: 0.8562 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 0s 786ms/step - accuracy: 0.8563 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 0s 780ms/step - accuracy: 0.8564 - loss: 0.44 ━━━━━━━━━━━━━━━━━━━━ 52s 800ms/step - accuracy: 0.8565 - loss: 0.4471 - val_accuracy: 0.5417 - val_loss: 2.1864\n",
      "Epoch 16/20\n",
      "63/63 ━━━━━━━━━━━━━━━━━━━━ 23s 382ms/step - accuracy: 0.7812 - loss: 0.876 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - accuracy: 0.7812 - loss: 0.8764 - val_accuracy: 0.3478 - val_loss: 3.7498\n",
      "Epoch 17/20\n",
      "63/63 ━━━━━━━━━━━━━━━━━━━━ 36s 590ms/step - accuracy: 0.9375 - loss: 0.198 ━━━━━━━━━━━━━━━━━━━━ 25s 419ms/step - accuracy: 0.9297 - loss: 0.202 ━━━━━━━━━━━━━━━━━━━━ 24s 404ms/step - accuracy: 0.9219 - loss: 0.242 ━━━━━━━━━━━━━━━━━━━━ 23s 399ms/step - accuracy: 0.9199 - loss: 0.254 ━━━━━━━━━━━━━━━━━━━━ 24s 418ms/step - accuracy: 0.9209 - loss: 0.256 ━━━━━━━━━━━━━━━━━━━━ 24s 423ms/step - accuracy: 0.9211 - loss: 0.260 ━━━━━━━━━━━━━━━━━━━━ 24s 430ms/step - accuracy: 0.9202 - loss: 0.266 ━━━━━━━━━━━━━━━━━━━━ 24s 440ms/step - accuracy: 0.9200 - loss: 0.271 ━━━━━━━━━━━━━━━━━━━━ 23s 442ms/step - accuracy: 0.9188 - loss: 0.276 ━━━━━━━━━━━━━━━━━━━━ 26s 504ms/step - accuracy: 0.9185 - loss: 0.280 ━━━━━━━━━━━━━━━━━━━━ 29s 575ms/step - accuracy: 0.9176 - loss: 0.287 ━━━━━━━━━━━━━━━━━━━━ 28s 561ms/step - accuracy: 0.9171 - loss: 0.293 ━━━━━━━━━━━━━━━━━━━━ 31s 627ms/step - accuracy: 0.9164 - loss: 0.297 ━━━━━━━━━━━━━━━━━━━━ 32s 666ms/step - accuracy: 0.9158 - loss: 0.301 ━━━━━━━━━━━━━━━━━━━━ 33s 703ms/step - accuracy: 0.9151 - loss: 0.303 ━━━━━━━━━━━━━━━━━━━━ 34s 736ms/step - accuracy: 0.9146 - loss: 0.305 ━━━━━━━━━━━━━━━━━━━━ 35s 767ms/step - accuracy: 0.9140 - loss: 0.306 ━━━━━━━━━━━━━━━━━━━━ 35s 796ms/step - accuracy: 0.9134 - loss: 0.308 ━━━━━━━━━━━━━━━━━━━━ 36s 826ms/step - accuracy: 0.9128 - loss: 0.309 ━━━━━━━━━━━━━━━━━━━━ 36s 849ms/step - accuracy: 0.9122 - loss: 0.311 ━━━━━━━━━━━━━━━━━━━━ 36s 873ms/step - accuracy: 0.9115 - loss: 0.314 ━━━━━━━━━━━━━━━━━━━━ 36s 891ms/step - accuracy: 0.9107 - loss: 0.317 ━━━━━━━━━━━━━━━━━━━━ 36s 915ms/step - accuracy: 0.9098 - loss: 0.319 ━━━━━━━━━━━━━━━━━━━━ 36s 933ms/step - accuracy: 0.9090 - loss: 0.322 ━━━━━━━━━━━━━━━━━━━━ 36s 950ms/step - accuracy: 0.9082 - loss: 0.324 ━━━━━━━━━━━━━━━━━━━━ 35s 965ms/step - accuracy: 0.9077 - loss: 0.325 ━━━━━━━━━━━━━━━━━━━━ 35s 980ms/step - accuracy: 0.9071 - loss: 0.326 ━━━━━━━━━━━━━━━━━━━━ 34s 996ms/step - accuracy: 0.9065 - loss: 0.328 ━━━━━━━━━━━━━━━━━━━━ 34s 1s/step - accuracy: 0.9059 - loss: 0.3300  ━━━━━━━━━━━━━━━━━━━━ 33s 1s/step - accuracy: 0.9053 - loss: 0.33 ━━━━━━━━━━━━━━━━━━━━ 32s 1s/step - accuracy: 0.9047 - loss: 0.33 ━━━━━━━━━━━━━━━━━━━━ 32s 1s/step - accuracy: 0.9042 - loss: 0.33 ━━━━━━━━━━━━━━━━━━━━ 31s 1s/step - accuracy: 0.9036 - loss: 0.33 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.9031 - loss: 0.33 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.9026 - loss: 0.33 ━━━━━━━━━━━━━━━━━━━━ 28s 1s/step - accuracy: 0.9021 - loss: 0.33 ━━━━━━━━━━━━━━━━━━━━ 27s 1s/step - accuracy: 0.9016 - loss: 0.34 ━━━━━━━━━━━━━━━━━━━━ 27s 1s/step - accuracy: 0.9013 - loss: 0.34 ━━━━━━━━━━━━━━━━━━━━ 26s 1s/step - accuracy: 0.9009 - loss: 0.34 ━━━━━━━━━━━━━━━━━━━━ 25s 1s/step - accuracy: 0.9006 - loss: 0.34 ━━━━━━━━━━━━━━━━━━━━ 24s 1s/step - accuracy: 0.9003 - loss: 0.34 ━━━━━━━━━━━━━━━━━━━━ 23s 1s/step - accuracy: 0.9000 - loss: 0.34 ━━━━━━━━━━━━━━━━━━━━ 22s 1s/step - accuracy: 0.8996 - loss: 0.34 ━━━━━━━━━━━━━━━━━━━━ 21s 1s/step - accuracy: 0.8992 - loss: 0.34 ━━━━━━━━━━━━━━━━━━━━ 20s 1s/step - accuracy: 0.8989 - loss: 0.34 ━━━━━━━━━━━━━━━━━━━━ 19s 1s/step - accuracy: 0.8986 - loss: 0.34 ━━━━━━━━━━━━━━━━━━━━ 18s 1s/step - accuracy: 0.8983 - loss: 0.34 ━━━━━━━━━━━━━━━━━━━━ 17s 1s/step - accuracy: 0.8979 - loss: 0.34 ━━━━━━━━━━━━━━━━━━━━ 16s 1s/step - accuracy: 0.8976 - loss: 0.34 ━━━━━━━━━━━━━━━━━━━━ 14s 1s/step - accuracy: 0.8973 - loss: 0.34 ━━━━━━━━━━━━━━━━━━━━ 13s 1s/step - accuracy: 0.8970 - loss: 0.34 ━━━━━━━━━━━━━━━━━━━━ 12s 1s/step - accuracy: 0.8968 - loss: 0.35 ━━━━━━━━━━━━━━━━━━━━ 11s 1s/step - accuracy: 0.8964 - loss: 0.35 ━━━━━━━━━━━━━━━━━━━━ 10s 1s/step - accuracy: 0.8961 - loss: 0.35 ━━━━━━━━━━━━━━━━━━━━ 9s 1s/step - accuracy: 0.8958 - loss: 0.3523 ━━━━━━━━━━━━━━━━━━━━ 8s 1s/step - accuracy: 0.8955 - loss: 0.352 ━━━━━━━━━━━━━━━━━━━━ 7s 1s/step - accuracy: 0.8952 - loss: 0.353 ━━━━━━━━━━━━━━━━━━━━ 5s 1s/step - accuracy: 0.8949 - loss: 0.353 ━━━━━━━━━━━━━━━━━━━━ 4s 1s/step - accuracy: 0.8947 - loss: 0.353 ━━━━━━━━━━━━━━━━━━━━ 3s 1s/step - accuracy: 0.8944 - loss: 0.354 ━━━━━━━━━━━━━━━━━━━━ 2s 1s/step - accuracy: 0.8942 - loss: 0.354 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step - accuracy: 0.8940 - loss: 0.354 ━━━━━━━━━━━━━━━━━━━━ 0s 1s/step - accuracy: 0.8938 - loss: 0.355 ━━━━━━━━━━━━━━━━━━━━ 79s 1s/step - accuracy: 0.8936 - loss: 0.3554 - val_accuracy: 0.5979 - val_loss: 1.6913\n",
      "Epoch 18/20\n",
      "63/63 ━━━━━━━━━━━━━━━━━━━━ 1:23 1s/step - accuracy: 0.8750 - loss: 0.350 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - accuracy: 0.8750 - loss: 0.3506 - val_accuracy: 0.4783 - val_loss: 1.6449\n",
      "Epoch 19/20\n",
      "63/63 ━━━━━━━━━━━━━━━━━━━━ 1:58 2s/step - accuracy: 0.9062 - loss: 0.228 ━━━━━━━━━━━━━━━━━━━━ 1:22 1s/step - accuracy: 0.9141 - loss: 0.210 ━━━━━━━━━━━━━━━━━━━━ 1:21 1s/step - accuracy: 0.9184 - loss: 0.212 ━━━━━━━━━━━━━━━━━━━━ 1:20 1s/step - accuracy: 0.9193 - loss: 0.210 ━━━━━━━━━━━━━━━━━━━━ 1:19 1s/step - accuracy: 0.9192 - loss: 0.224 ━━━━━━━━━━━━━━━━━━━━ 1:18 1s/step - accuracy: 0.9196 - loss: 0.231 ━━━━━━━━━━━━━━━━━━━━ 1:17 1s/step - accuracy: 0.9209 - loss: 0.234 ━━━━━━━━━━━━━━━━━━━━ 1:15 1s/step - accuracy: 0.9220 - loss: 0.236 ━━━━━━━━━━━━━━━━━━━━ 1:08 1s/step - accuracy: 0.9231 - loss: 0.237 ━━━━━━━━━━━━━━━━━━━━ 1:06 1s/step - accuracy: 0.9237 - loss: 0.238 ━━━━━━━━━━━━━━━━━━━━ 1:06 1s/step - accuracy: 0.9231 - loss: 0.241 ━━━━━━━━━━━━━━━━━━━━ 1:04 1s/step - accuracy: 0.9231 - loss: 0.243 ━━━━━━━━━━━━━━━━━━━━ 1:03 1s/step - accuracy: 0.9227 - loss: 0.244 ━━━━━━━━━━━━━━━━━━━━ 1:01 1s/step - accuracy: 0.9217 - loss: 0.247 ━━━━━━━━━━━━━━━━━━━━ 1:00 1s/step - accuracy: 0.9204 - loss: 0.250 ━━━━━━━━━━━━━━━━━━━━ 59s 1s/step - accuracy: 0.9195 - loss: 0.252 ━━━━━━━━━━━━━━━━━━━━ 58s 1s/step - accuracy: 0.9191 - loss: 0.25 ━━━━━━━━━━━━━━━━━━━━ 56s 1s/step - accuracy: 0.9185 - loss: 0.25 ━━━━━━━━━━━━━━━━━━━━ 55s 1s/step - accuracy: 0.9181 - loss: 0.25 ━━━━━━━━━━━━━━━━━━━━ 54s 1s/step - accuracy: 0.9178 - loss: 0.25 ━━━━━━━━━━━━━━━━━━━━ 53s 1s/step - accuracy: 0.9175 - loss: 0.25 ━━━━━━━━━━━━━━━━━━━━ 52s 1s/step - accuracy: 0.9173 - loss: 0.25 ━━━━━━━━━━━━━━━━━━━━ 51s 1s/step - accuracy: 0.9170 - loss: 0.25 ━━━━━━━━━━━━━━━━━━━━ 50s 1s/step - accuracy: 0.9169 - loss: 0.25 ━━━━━━━━━━━━━━━━━━━━ 48s 1s/step - accuracy: 0.9167 - loss: 0.25 ━━━━━━━━━━━━━━━━━━━━ 47s 1s/step - accuracy: 0.9165 - loss: 0.25 ━━━━━━━━━━━━━━━━━━━━ 46s 1s/step - accuracy: 0.9164 - loss: 0.25 ━━━━━━━━━━━━━━━━━━━━ 45s 1s/step - accuracy: 0.9163 - loss: 0.25 ━━━━━━━━━━━━━━━━━━━━ 43s 1s/step - accuracy: 0.9163 - loss: 0.25 ━━━━━━━━━━━━━━━━━━━━ 42s 1s/step - accuracy: 0.9163 - loss: 0.25 ━━━━━━━━━━━━━━━━━━━━ 41s 1s/step - accuracy: 0.9162 - loss: 0.25 ━━━━━━━━━━━━━━━━━━━━ 40s 1s/step - accuracy: 0.9161 - loss: 0.25 ━━━━━━━━━━━━━━━━━━━━ 39s 1s/step - accuracy: 0.9160 - loss: 0.26 ━━━━━━━━━━━━━━━━━━━━ 37s 1s/step - accuracy: 0.9160 - loss: 0.26 ━━━━━━━━━━━━━━━━━━━━ 36s 1s/step - accuracy: 0.9160 - loss: 0.26 ━━━━━━━━━━━━━━━━━━━━ 35s 1s/step - accuracy: 0.9158 - loss: 0.26 ━━━━━━━━━━━━━━━━━━━━ 34s 1s/step - accuracy: 0.9157 - loss: 0.26 ━━━━━━━━━━━━━━━━━━━━ 32s 1s/step - accuracy: 0.9156 - loss: 0.26 ━━━━━━━━━━━━━━━━━━━━ 31s 1s/step - accuracy: 0.9154 - loss: 0.26 ━━━━━━━━━━━━━━━━━━━━ 30s 1s/step - accuracy: 0.9152 - loss: 0.26 ━━━━━━━━━━━━━━━━━━━━ 29s 1s/step - accuracy: 0.9150 - loss: 0.26 ━━━━━━━━━━━━━━━━━━━━ 27s 1s/step - accuracy: 0.9148 - loss: 0.26 ━━━━━━━━━━━━━━━━━━━━ 26s 1s/step - accuracy: 0.9146 - loss: 0.26 ━━━━━━━━━━━━━━━━━━━━ 25s 1s/step - accuracy: 0.9144 - loss: 0.26 ━━━━━━━━━━━━━━━━━━━━ 23s 1s/step - accuracy: 0.9141 - loss: 0.26 ━━━━━━━━━━━━━━━━━━━━ 22s 1s/step - accuracy: 0.9139 - loss: 0.26 ━━━━━━━━━━━━━━━━━━━━ 21s 1s/step - accuracy: 0.9136 - loss: 0.26 ━━━━━━━━━━━━━━━━━━━━ 19s 1s/step - accuracy: 0.9134 - loss: 0.26 ━━━━━━━━━━━━━━━━━━━━ 18s 1s/step - accuracy: 0.9131 - loss: 0.26 ━━━━━━━━━━━━━━━━━━━━ 17s 1s/step - accuracy: 0.9129 - loss: 0.27 ━━━━━━━━━━━━━━━━━━━━ 15s 1s/step - accuracy: 0.9127 - loss: 0.27 ━━━━━━━━━━━━━━━━━━━━ 14s 1s/step - accuracy: 0.9125 - loss: 0.27 ━━━━━━━━━━━━━━━━━━━━ 13s 1s/step - accuracy: 0.9123 - loss: 0.27 ━━━━━━━━━━━━━━━━━━━━ 12s 1s/step - accuracy: 0.9122 - loss: 0.27 ━━━━━━━━━━━━━━━━━━━━ 10s 1s/step - accuracy: 0.9120 - loss: 0.27 ━━━━━━━━━━━━━━━━━━━━ 9s 1s/step - accuracy: 0.9118 - loss: 0.2732 ━━━━━━━━━━━━━━━━━━━━ 8s 1s/step - accuracy: 0.9115 - loss: 0.273 ━━━━━━━━━━━━━━━━━━━━ 6s 1s/step - accuracy: 0.9114 - loss: 0.274 ━━━━━━━━━━━━━━━━━━━━ 5s 1s/step - accuracy: 0.9112 - loss: 0.274 ━━━━━━━━━━━━━━━━━━━━ 4s 1s/step - accuracy: 0.9110 - loss: 0.275 ━━━━━━━━━━━━━━━━━━━━ 2s 1s/step - accuracy: 0.9108 - loss: 0.275 ━━━━━━━━━━━━━━━━━━━━ 1s 1s/step - accuracy: 0.9106 - loss: 0.276 ━━━━━━━━━━━━━━━━━━━━ 0s 1s/step - accuracy: 0.9104 - loss: 0.276 ━━━━━━━━━━━━━━━━━━━━ 90s 1s/step - accuracy: 0.9102 - loss: 0.2773 - val_accuracy: 0.5042 - val_loss: 2.3894\n",
      "Epoch 20/20\n",
      "63/63 ━━━━━━━━━━━━━━━━━━━━ 1:29 1s/step - accuracy: 0.8750 - loss: 0.328 ━━━━━━━━━━━━━━━━━━━━ 2s 4ms/step - accuracy: 0.8750 - loss: 0.3281 - val_accuracy: 0.3913 - val_loss: 2.9568\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>▁▂▃▄▄▅▅▅▆▆▆▇▇▇▇▆████</td></tr><tr><td>epoch/epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>epoch/loss</td><td>█▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch/val_accuracy</td><td>▃▃▂▂▁▂▃▁▃▃▃▃▄▆▇▅█▆▇▅</td></tr><tr><td>epoch/val_loss</td><td>▄▃▇▇█▇▄▄▅▅▄▃▂▁▁▃▁▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch/accuracy</td><td>0.875</td></tr><tr><td>epoch/epoch</td><td>19</td></tr><tr><td>epoch/loss</td><td>0.32806</td></tr><tr><td>epoch/val_accuracy</td><td>0.3913</td></tr><tr><td>epoch/val_loss</td><td>2.9568</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">devoted-totem-30</strong> at: <a href='https://wandb.ai/adamata-selection/wandb-trash-classification/runs/j0ku1651' target=\"_blank\">https://wandb.ai/adamata-selection/wandb-trash-classification/runs/j0ku1651</a><br/> View project at: <a href='https://wandb.ai/adamata-selection/wandb-trash-classification' target=\"_blank\">https://wandb.ai/adamata-selection/wandb-trash-classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240520_134847-j0ku1651\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project=\"wandb-trash-classification\",\n",
    "    config={\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"loss\": \"categorical_crossentropy\",\n",
    "    \"metric\": \"accuracy\",\n",
    "    \"epoch\": 20,\n",
    "    \"batch_size\": 32\n",
    "    }\n",
    ")\n",
    "\n",
    "n_class = 6\n",
    "\n",
    "# Assuming the following config values are set in wandb:\n",
    "loss = run.config[\"loss\"]\n",
    "metrics = run.config[\"metric\"]\n",
    "epochs = run.config[\"epoch\"]\n",
    "learning_rate = run.config[\"learning_rate\"]\n",
    "batch_size = run.config['batch_size']\n",
    "\n",
    "i = Input(shape=(128, 128, 3))\n",
    "\n",
    "# Convolutional Layers {Conv --> BatchNorm --> Conv --> BatchNorm --> MaxPooling (3x)}\n",
    "x = Conv2D(32, (3, 3), padding='same', activation='relu')(i)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(32, (3, 3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Neural Networks Layer\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(n_class, activation='softmax')(x)\n",
    "\n",
    "model = Model(i, x)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "              loss=loss, \n",
    "              metrics=[metrics])\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[WandbMetricsLogger()]\n",
    ")\n",
    "\n",
    "# Save model locally\n",
    "path = \"model.keras\"\n",
    "model.save(path)\n",
    "\n",
    "# Save model to W&B\n",
    "path = \"./model.keras\"\n",
    "registered_model_name = \"trash-classification-dev\"\n",
    "\n",
    "run.link_model(path=path, registered_model_name=registered_model_name)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d1b0fa3d-b8b5-463d-b489-455742e7dd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\adven\\Documents\\DSTI\\Career\\Applications\\Adamata\\trash-classification\\wandb\\run-20240520_131742-r6q64hnl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adamata-selection/wandb-trash-classification/runs/r6q64hnl' target=\"_blank\">ethereal-sky-23</a></strong> to <a href='https://wandb.ai/adamata-selection/wandb-trash-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adamata-selection/wandb-trash-classification' target=\"_blank\">https://wandb.ai/adamata-selection/wandb-trash-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adamata-selection/wandb-trash-classification/runs/r6q64hnl' target=\"_blank\">https://wandb.ai/adamata-selection/wandb-trash-classification/runs/r6q64hnl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:   2526 of 2526 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 30.9%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ethereal-sky-23</strong> at: <a href='https://wandb.ai/adamata-selection/wandb-trash-classification/runs/r6q64hnl' target=\"_blank\">https://wandb.ai/adamata-selection/wandb-trash-classification/runs/r6q64hnl</a><br/> View project at: <a href='https://wandb.ai/adamata-selection/wandb-trash-classification' target=\"_blank\">https://wandb.ai/adamata-selection/wandb-trash-classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240520_131742-r6q64hnl\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "job_type = \"train_model\"\n",
    "\n",
    "config={\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"loss\": \"categorical_crossentropy\",\n",
    "    \"metric\": \"accuracy\",\n",
    "    \"epoch\": 20,\n",
    "    \"batch_size\": 32\n",
    "}\n",
    "\n",
    "# Initialize a W&B run\n",
    "run = wandb.init(project=project, job_type=job_type, config=config)\n",
    "\n",
    "# Retrieve the dataset artifact\n",
    "version = \"latest\"\n",
    "name = \"{}:{}\".format(\"{}_dataset\".format(model_use_case_id), version)\n",
    "artifact = run.use_artifact(artifact_or_name=name)\n",
    "\n",
    "# Get specific content from the dataframe\n",
    "train_table = artifact.get(\"train_table\")\n",
    "x_train = train_table.get_column(\"x_train\", convert_to=\"numpy\")\n",
    "y_train = train_table.get_column(\"y_train\", convert_to=\"numpy\")\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f9d6a0d7-3f43-467d-bdac-90e2d7852225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5f876baf-52d3-4f1d-b4ab-23bb2cfc9870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ubb93tdz) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classic-deluge-24</strong> at: <a href='https://wandb.ai/adamata-selection/wandb-trash-classification/runs/ubb93tdz' target=\"_blank\">https://wandb.ai/adamata-selection/wandb-trash-classification/runs/ubb93tdz</a><br/> View project at: <a href='https://wandb.ai/adamata-selection/wandb-trash-classification' target=\"_blank\">https://wandb.ai/adamata-selection/wandb-trash-classification</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240520_132142-ubb93tdz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ubb93tdz). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\adven\\Documents\\DSTI\\Career\\Applications\\Adamata\\trash-classification\\wandb\\run-20240520_133102-vnm13aay</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adamata-selection/wandb-trash-classification/runs/vnm13aay' target=\"_blank\">good-violet-25</a></strong> to <a href='https://wandb.ai/adamata-selection/wandb-trash-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adamata-selection/wandb-trash-classification' target=\"_blank\">https://wandb.ai/adamata-selection/wandb-trash-classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adamata-selection/wandb-trash-classification/runs/vnm13aay' target=\"_blank\">https://wandb.ai/adamata-selection/wandb-trash-classification/runs/vnm13aay</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None, 6, 6, 6, 6, 1), output.shape=(None, 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 53\u001b[0m\n\u001b[0;32m     50\u001b[0m x_t, x_v, y_t, y_v \u001b[38;5;241m=\u001b[39m train_test_split(x_train, y_train, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.33\u001b[39m)\n\u001b[0;32m     51\u001b[0m x_t, x_v, y_t, y_v \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(x_t, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), np\u001b[38;5;241m.\u001b[39mexpand_dims(x_v, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), np\u001b[38;5;241m.\u001b[39mexpand_dims(y_t, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), np\u001b[38;5;241m.\u001b[39mexpand_dims(y_v, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \n\u001b[1;32m---> 53\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_t\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_v\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mWandbMetricsLogger\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Save model locally\u001b[39;00m\n\u001b[0;32m     63\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\trash-classification\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\trash-classification\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:547\u001b[0m, in \u001b[0;36mcategorical_crossentropy\u001b[1;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[0;32m    541\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    542\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must be at least rank 1. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    543\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    544\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    545\u001b[0m     )\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[1;32m--> 547\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    548\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArguments `target` and `output` must have the same rank \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    549\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(ndim). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    550\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    551\u001b[0m     )\n\u001b[0;32m    552\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target\u001b[38;5;241m.\u001b[39mshape, output\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 \u001b[38;5;241m!=\u001b[39m e2:\n",
      "\u001b[1;31mValueError\u001b[0m: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(None, 6, 6, 6, 6, 1), output.shape=(None, 6)"
     ]
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"wandb-trash-classification\"\n",
    ")\n",
    "\n",
    "\n",
    "n_class = 6\n",
    "# input_shape = (128, 128, 3)\n",
    "\n",
    "loss = run.config[\"loss\"]\n",
    "metrics = run.config[\"metric\"]\n",
    "epochs = run.config[\"epoch\"]\n",
    "learning_rate = run.config[\"learning_rate\"]\n",
    "\n",
    "i = Input(shape=(128, 128, 3))\n",
    "\n",
    "# Convolutional Layers {Conv --> BatchNorm --> Conv --> BatchNorm --> MaxPooling (3x)}\n",
    "x = Conv2D(32, (3,3), padding='same', activation='relu')(i)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(32, (3,3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(64, (3,3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, (3,3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "x = Conv2D(128, (3,3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(128, (3,3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "\n",
    "# Neural Networks Layer\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(n_class, activation='softmax')(x)\n",
    "\n",
    "model = Model(i, x)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), \n",
    "          loss=loss, \n",
    "          metrics=[run.config['metric']])\n",
    "\n",
    "# Generate labels for training data\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "# Create training and test set\n",
    "x_t, x_v, y_t, y_v = train_test_split(x_train, y_train, test_size=0.33)\n",
    "\n",
    "model.fit(\n",
    "    x=x_t,\n",
    "    y=y_t,\n",
    "    batch_size=run.config['batch_size'],\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_v, y_v),\n",
    "    callbacks=[WandbMetricsLogger()]\n",
    ")\n",
    "\n",
    "# Save model locally\n",
    "path = \"model.keras\"\n",
    "model.save(path)\n",
    "\n",
    "path = \"./model.h5\"\n",
    "registered_model_name = \"trash-classification-dev\"\n",
    "\n",
    "run.link_model(path=path, registered_model_name=registered_model_name)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e996c5e2-8df4-46de-8678-98a3b47ffccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1356, 128, 128, 3), (668, 128, 128, 3), (1356, 6, 6, 6), (668, 6, 6, 6))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t.shape, x_v.shape, y_t.shape, y_v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "36e615cd-4e46-4e9c-817d-f217bf89f090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1356, 128, 128, 3, 1),\n",
       " (668, 128, 128, 3, 1),\n",
       " (1356, 6, 6, 6, 1),\n",
       " (668, 6, 6, 6, 1))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(x_t, -1).shape, np.expand_dims(x_v, -1).shape, np.expand_dims(y_t, -1).shape, np.expand_dims(y_v, -1).shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3eadf71e-22c2-46b4-b257-1e1a2120e13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[[238],\n",
       "          [234],\n",
       "          [223]],\n",
       "\n",
       "         [[238],\n",
       "          [234],\n",
       "          [223]],\n",
       "\n",
       "         [[236],\n",
       "          [232],\n",
       "          [221]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[218],\n",
       "          [208],\n",
       "          [198]],\n",
       "\n",
       "         [[208],\n",
       "          [198],\n",
       "          [188]],\n",
       "\n",
       "         [[211],\n",
       "          [201],\n",
       "          [191]]],\n",
       "\n",
       "\n",
       "        [[[237],\n",
       "          [233],\n",
       "          [222]],\n",
       "\n",
       "         [[237],\n",
       "          [233],\n",
       "          [222]],\n",
       "\n",
       "         [[235],\n",
       "          [231],\n",
       "          [220]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[217],\n",
       "          [207],\n",
       "          [197]],\n",
       "\n",
       "         [[207],\n",
       "          [197],\n",
       "          [187]],\n",
       "\n",
       "         [[210],\n",
       "          [200],\n",
       "          [190]]],\n",
       "\n",
       "\n",
       "        [[[236],\n",
       "          [232],\n",
       "          [221]],\n",
       "\n",
       "         [[236],\n",
       "          [232],\n",
       "          [221]],\n",
       "\n",
       "         [[235],\n",
       "          [231],\n",
       "          [220]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[216],\n",
       "          [206],\n",
       "          [196]],\n",
       "\n",
       "         [[206],\n",
       "          [196],\n",
       "          [186]],\n",
       "\n",
       "         [[209],\n",
       "          [199],\n",
       "          [189]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[209],\n",
       "          [197],\n",
       "          [183]],\n",
       "\n",
       "         [[207],\n",
       "          [195],\n",
       "          [181]],\n",
       "\n",
       "         [[206],\n",
       "          [194],\n",
       "          [180]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[190],\n",
       "          [181],\n",
       "          [166]],\n",
       "\n",
       "         [[189],\n",
       "          [180],\n",
       "          [165]],\n",
       "\n",
       "         [[182],\n",
       "          [173],\n",
       "          [158]]],\n",
       "\n",
       "\n",
       "        [[[209],\n",
       "          [197],\n",
       "          [183]],\n",
       "\n",
       "         [[207],\n",
       "          [195],\n",
       "          [181]],\n",
       "\n",
       "         [[206],\n",
       "          [194],\n",
       "          [180]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[189],\n",
       "          [180],\n",
       "          [165]],\n",
       "\n",
       "         [[188],\n",
       "          [179],\n",
       "          [164]],\n",
       "\n",
       "         [[183],\n",
       "          [174],\n",
       "          [159]]],\n",
       "\n",
       "\n",
       "        [[[209],\n",
       "          [197],\n",
       "          [183]],\n",
       "\n",
       "         [[207],\n",
       "          [195],\n",
       "          [181]],\n",
       "\n",
       "         [[206],\n",
       "          [194],\n",
       "          [180]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[188],\n",
       "          [179],\n",
       "          [164]],\n",
       "\n",
       "         [[187],\n",
       "          [178],\n",
       "          [163]],\n",
       "\n",
       "         [[184],\n",
       "          [175],\n",
       "          [160]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[255],\n",
       "          [255],\n",
       "          [255]],\n",
       "\n",
       "         [[255],\n",
       "          [255],\n",
       "          [255]],\n",
       "\n",
       "         [[255],\n",
       "          [255],\n",
       "          [255]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[158],\n",
       "          [158],\n",
       "          [156]],\n",
       "\n",
       "         [[159],\n",
       "          [159],\n",
       "          [157]],\n",
       "\n",
       "         [[159],\n",
       "          [159],\n",
       "          [157]]],\n",
       "\n",
       "\n",
       "        [[[255],\n",
       "          [255],\n",
       "          [255]],\n",
       "\n",
       "         [[255],\n",
       "          [255],\n",
       "          [255]],\n",
       "\n",
       "         [[255],\n",
       "          [255],\n",
       "          [255]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[156],\n",
       "          [156],\n",
       "          [154]],\n",
       "\n",
       "         [[158],\n",
       "          [158],\n",
       "          [156]],\n",
       "\n",
       "         [[158],\n",
       "          [158],\n",
       "          [156]]],\n",
       "\n",
       "\n",
       "        [[[255],\n",
       "          [255],\n",
       "          [255]],\n",
       "\n",
       "         [[255],\n",
       "          [255],\n",
       "          [255]],\n",
       "\n",
       "         [[255],\n",
       "          [255],\n",
       "          [255]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[156],\n",
       "          [156],\n",
       "          [154]],\n",
       "\n",
       "         [[157],\n",
       "          [157],\n",
       "          [155]],\n",
       "\n",
       "         [[157],\n",
       "          [157],\n",
       "          [155]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[198],\n",
       "          [199],\n",
       "          [181]],\n",
       "\n",
       "         [[200],\n",
       "          [202],\n",
       "          [188]],\n",
       "\n",
       "         [[195],\n",
       "          [198],\n",
       "          [187]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[172],\n",
       "          [170],\n",
       "          [155]],\n",
       "\n",
       "         [[180],\n",
       "          [178],\n",
       "          [163]],\n",
       "\n",
       "         [[167],\n",
       "          [165],\n",
       "          [150]]],\n",
       "\n",
       "\n",
       "        [[[202],\n",
       "          [203],\n",
       "          [185]],\n",
       "\n",
       "         [[190],\n",
       "          [192],\n",
       "          [178]],\n",
       "\n",
       "         [[182],\n",
       "          [185],\n",
       "          [174]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[171],\n",
       "          [169],\n",
       "          [154]],\n",
       "\n",
       "         [[177],\n",
       "          [175],\n",
       "          [160]],\n",
       "\n",
       "         [[177],\n",
       "          [175],\n",
       "          [160]]],\n",
       "\n",
       "\n",
       "        [[[201],\n",
       "          [202],\n",
       "          [184]],\n",
       "\n",
       "         [[194],\n",
       "          [196],\n",
       "          [182]],\n",
       "\n",
       "         [[187],\n",
       "          [190],\n",
       "          [179]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[175],\n",
       "          [173],\n",
       "          [158]],\n",
       "\n",
       "         [[152],\n",
       "          [150],\n",
       "          [135]],\n",
       "\n",
       "         [[143],\n",
       "          [141],\n",
       "          [126]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[239],\n",
       "          [213],\n",
       "          [188]],\n",
       "\n",
       "         [[239],\n",
       "          [213],\n",
       "          [188]],\n",
       "\n",
       "         [[239],\n",
       "          [213],\n",
       "          [188]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[242],\n",
       "          [216],\n",
       "          [191]],\n",
       "\n",
       "         [[242],\n",
       "          [216],\n",
       "          [191]],\n",
       "\n",
       "         [[242],\n",
       "          [216],\n",
       "          [191]]],\n",
       "\n",
       "\n",
       "        [[[240],\n",
       "          [214],\n",
       "          [189]],\n",
       "\n",
       "         [[240],\n",
       "          [214],\n",
       "          [189]],\n",
       "\n",
       "         [[239],\n",
       "          [213],\n",
       "          [188]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[242],\n",
       "          [216],\n",
       "          [191]],\n",
       "\n",
       "         [[242],\n",
       "          [216],\n",
       "          [191]],\n",
       "\n",
       "         [[242],\n",
       "          [216],\n",
       "          [191]]],\n",
       "\n",
       "\n",
       "        [[[237],\n",
       "          [211],\n",
       "          [186]],\n",
       "\n",
       "         [[237],\n",
       "          [211],\n",
       "          [186]],\n",
       "\n",
       "         [[239],\n",
       "          [213],\n",
       "          [188]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[242],\n",
       "          [216],\n",
       "          [191]],\n",
       "\n",
       "         [[242],\n",
       "          [216],\n",
       "          [191]],\n",
       "\n",
       "         [[242],\n",
       "          [216],\n",
       "          [191]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[221],\n",
       "          [201],\n",
       "          [177]],\n",
       "\n",
       "         [[219],\n",
       "          [199],\n",
       "          [175]],\n",
       "\n",
       "         [[219],\n",
       "          [199],\n",
       "          [175]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[178],\n",
       "          [157],\n",
       "          [130]],\n",
       "\n",
       "         [[180],\n",
       "          [156],\n",
       "          [130]],\n",
       "\n",
       "         [[181],\n",
       "          [155],\n",
       "          [130]]],\n",
       "\n",
       "\n",
       "        [[[221],\n",
       "          [201],\n",
       "          [177]],\n",
       "\n",
       "         [[219],\n",
       "          [199],\n",
       "          [175]],\n",
       "\n",
       "         [[219],\n",
       "          [199],\n",
       "          [175]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[178],\n",
       "          [157],\n",
       "          [130]],\n",
       "\n",
       "         [[180],\n",
       "          [156],\n",
       "          [130]],\n",
       "\n",
       "         [[181],\n",
       "          [155],\n",
       "          [130]]],\n",
       "\n",
       "\n",
       "        [[[221],\n",
       "          [201],\n",
       "          [177]],\n",
       "\n",
       "         [[219],\n",
       "          [199],\n",
       "          [175]],\n",
       "\n",
       "         [[219],\n",
       "          [199],\n",
       "          [175]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[178],\n",
       "          [157],\n",
       "          [130]],\n",
       "\n",
       "         [[180],\n",
       "          [156],\n",
       "          [130]],\n",
       "\n",
       "         [[181],\n",
       "          [155],\n",
       "          [130]]]],\n",
       "\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "\n",
       "       [[[[218],\n",
       "          [212],\n",
       "          [180]],\n",
       "\n",
       "         [[216],\n",
       "          [210],\n",
       "          [178]],\n",
       "\n",
       "         [[219],\n",
       "          [213],\n",
       "          [181]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[160],\n",
       "          [154],\n",
       "          [120]],\n",
       "\n",
       "         [[158],\n",
       "          [152],\n",
       "          [118]],\n",
       "\n",
       "         [[157],\n",
       "          [151],\n",
       "          [117]]],\n",
       "\n",
       "\n",
       "        [[[218],\n",
       "          [212],\n",
       "          [180]],\n",
       "\n",
       "         [[216],\n",
       "          [210],\n",
       "          [178]],\n",
       "\n",
       "         [[219],\n",
       "          [213],\n",
       "          [181]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[159],\n",
       "          [153],\n",
       "          [119]],\n",
       "\n",
       "         [[157],\n",
       "          [151],\n",
       "          [117]],\n",
       "\n",
       "         [[156],\n",
       "          [150],\n",
       "          [116]]],\n",
       "\n",
       "\n",
       "        [[[218],\n",
       "          [212],\n",
       "          [180]],\n",
       "\n",
       "         [[216],\n",
       "          [210],\n",
       "          [178]],\n",
       "\n",
       "         [[219],\n",
       "          [213],\n",
       "          [181]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[158],\n",
       "          [152],\n",
       "          [118]],\n",
       "\n",
       "         [[157],\n",
       "          [151],\n",
       "          [117]],\n",
       "\n",
       "         [[155],\n",
       "          [149],\n",
       "          [115]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[220],\n",
       "          [218],\n",
       "          [197]],\n",
       "\n",
       "         [[222],\n",
       "          [220],\n",
       "          [199]],\n",
       "\n",
       "         [[219],\n",
       "          [217],\n",
       "          [196]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[171],\n",
       "          [165],\n",
       "          [143]],\n",
       "\n",
       "         [[170],\n",
       "          [164],\n",
       "          [142]],\n",
       "\n",
       "         [[168],\n",
       "          [162],\n",
       "          [140]]],\n",
       "\n",
       "\n",
       "        [[[220],\n",
       "          [218],\n",
       "          [197]],\n",
       "\n",
       "         [[222],\n",
       "          [220],\n",
       "          [199]],\n",
       "\n",
       "         [[220],\n",
       "          [218],\n",
       "          [197]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[172],\n",
       "          [166],\n",
       "          [144]],\n",
       "\n",
       "         [[170],\n",
       "          [164],\n",
       "          [142]],\n",
       "\n",
       "         [[169],\n",
       "          [163],\n",
       "          [141]]],\n",
       "\n",
       "\n",
       "        [[[220],\n",
       "          [218],\n",
       "          [197]],\n",
       "\n",
       "         [[222],\n",
       "          [220],\n",
       "          [199]],\n",
       "\n",
       "         [[221],\n",
       "          [219],\n",
       "          [198]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[173],\n",
       "          [167],\n",
       "          [145]],\n",
       "\n",
       "         [[171],\n",
       "          [165],\n",
       "          [143]],\n",
       "\n",
       "         [[170],\n",
       "          [164],\n",
       "          [142]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[220],\n",
       "          [210],\n",
       "          [201]],\n",
       "\n",
       "         [[218],\n",
       "          [208],\n",
       "          [199]],\n",
       "\n",
       "         [[220],\n",
       "          [210],\n",
       "          [201]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[198],\n",
       "          [186],\n",
       "          [164]],\n",
       "\n",
       "         [[197],\n",
       "          [185],\n",
       "          [163]],\n",
       "\n",
       "         [[196],\n",
       "          [184],\n",
       "          [162]]],\n",
       "\n",
       "\n",
       "        [[[220],\n",
       "          [210],\n",
       "          [201]],\n",
       "\n",
       "         [[218],\n",
       "          [208],\n",
       "          [199]],\n",
       "\n",
       "         [[220],\n",
       "          [210],\n",
       "          [201]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[196],\n",
       "          [184],\n",
       "          [162]],\n",
       "\n",
       "         [[195],\n",
       "          [183],\n",
       "          [161]],\n",
       "\n",
       "         [[194],\n",
       "          [182],\n",
       "          [160]]],\n",
       "\n",
       "\n",
       "        [[[220],\n",
       "          [210],\n",
       "          [201]],\n",
       "\n",
       "         [[218],\n",
       "          [208],\n",
       "          [199]],\n",
       "\n",
       "         [[220],\n",
       "          [210],\n",
       "          [201]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[194],\n",
       "          [182],\n",
       "          [160]],\n",
       "\n",
       "         [[193],\n",
       "          [181],\n",
       "          [159]],\n",
       "\n",
       "         [[192],\n",
       "          [180],\n",
       "          [158]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[217],\n",
       "          [212],\n",
       "          [208]],\n",
       "\n",
       "         [[219],\n",
       "          [214],\n",
       "          [210]],\n",
       "\n",
       "         [[219],\n",
       "          [214],\n",
       "          [210]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[229],\n",
       "          [219],\n",
       "          [207]],\n",
       "\n",
       "         [[228],\n",
       "          [218],\n",
       "          [206]],\n",
       "\n",
       "         [[226],\n",
       "          [216],\n",
       "          [204]]],\n",
       "\n",
       "\n",
       "        [[[217],\n",
       "          [212],\n",
       "          [208]],\n",
       "\n",
       "         [[218],\n",
       "          [213],\n",
       "          [209]],\n",
       "\n",
       "         [[218],\n",
       "          [213],\n",
       "          [209]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[229],\n",
       "          [219],\n",
       "          [207]],\n",
       "\n",
       "         [[228],\n",
       "          [218],\n",
       "          [206]],\n",
       "\n",
       "         [[226],\n",
       "          [216],\n",
       "          [204]]],\n",
       "\n",
       "\n",
       "        [[[216],\n",
       "          [211],\n",
       "          [207]],\n",
       "\n",
       "         [[217],\n",
       "          [212],\n",
       "          [208]],\n",
       "\n",
       "         [[217],\n",
       "          [212],\n",
       "          [208]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[229],\n",
       "          [219],\n",
       "          [207]],\n",
       "\n",
       "         [[228],\n",
       "          [218],\n",
       "          [206]],\n",
       "\n",
       "         [[226],\n",
       "          [216],\n",
       "          [204]]]],\n",
       "\n",
       "\n",
       "\n",
       "       [[[[226],\n",
       "          [214],\n",
       "          [198]],\n",
       "\n",
       "         [[226],\n",
       "          [214],\n",
       "          [198]],\n",
       "\n",
       "         [[224],\n",
       "          [212],\n",
       "          [196]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[192],\n",
       "          [177],\n",
       "          [158]],\n",
       "\n",
       "         [[192],\n",
       "          [177],\n",
       "          [158]],\n",
       "\n",
       "         [[192],\n",
       "          [177],\n",
       "          [158]]],\n",
       "\n",
       "\n",
       "        [[[225],\n",
       "          [213],\n",
       "          [197]],\n",
       "\n",
       "         [[225],\n",
       "          [213],\n",
       "          [197]],\n",
       "\n",
       "         [[223],\n",
       "          [211],\n",
       "          [195]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[192],\n",
       "          [177],\n",
       "          [158]],\n",
       "\n",
       "         [[192],\n",
       "          [177],\n",
       "          [158]],\n",
       "\n",
       "         [[192],\n",
       "          [177],\n",
       "          [158]]],\n",
       "\n",
       "\n",
       "        [[[224],\n",
       "          [212],\n",
       "          [196]],\n",
       "\n",
       "         [[224],\n",
       "          [212],\n",
       "          [196]],\n",
       "\n",
       "         [[222],\n",
       "          [210],\n",
       "          [194]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[192],\n",
       "          [177],\n",
       "          [158]],\n",
       "\n",
       "         [[192],\n",
       "          [177],\n",
       "          [158]],\n",
       "\n",
       "         [[192],\n",
       "          [177],\n",
       "          [158]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[181],\n",
       "          [171],\n",
       "          [162]],\n",
       "\n",
       "         [[179],\n",
       "          [169],\n",
       "          [160]],\n",
       "\n",
       "         [[179],\n",
       "          [169],\n",
       "          [160]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[134],\n",
       "          [123],\n",
       "          [103]],\n",
       "\n",
       "         [[133],\n",
       "          [121],\n",
       "          [105]],\n",
       "\n",
       "         [[131],\n",
       "          [119],\n",
       "          [103]]],\n",
       "\n",
       "\n",
       "        [[[181],\n",
       "          [171],\n",
       "          [162]],\n",
       "\n",
       "         [[179],\n",
       "          [169],\n",
       "          [160]],\n",
       "\n",
       "         [[179],\n",
       "          [169],\n",
       "          [160]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[134],\n",
       "          [123],\n",
       "          [103]],\n",
       "\n",
       "         [[133],\n",
       "          [121],\n",
       "          [105]],\n",
       "\n",
       "         [[132],\n",
       "          [120],\n",
       "          [104]]],\n",
       "\n",
       "\n",
       "        [[[181],\n",
       "          [171],\n",
       "          [162]],\n",
       "\n",
       "         [[179],\n",
       "          [169],\n",
       "          [160]],\n",
       "\n",
       "         [[179],\n",
       "          [169],\n",
       "          [160]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[134],\n",
       "          [123],\n",
       "          [103]],\n",
       "\n",
       "         [[134],\n",
       "          [122],\n",
       "          [106]],\n",
       "\n",
       "         [[133],\n",
       "          [121],\n",
       "          [105]]]]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(x_t, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e73bf3-7222-4d87-9adb-cc7b31fbe5d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
